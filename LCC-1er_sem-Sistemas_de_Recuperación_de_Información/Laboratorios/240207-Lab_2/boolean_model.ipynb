{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio#2: Modelos de recuperación de información\n",
    "\n",
    "Un Modelo de Recuperación de Información (MRI) es un sistema diseñado para facilitar la búsqueda y extracción de información relevante sobre grandes bases de datos, por lo general estos datos se asocian a documentos pero pueden trabajar también con imágenes, audios o videos, o sea, con archivos de multimedia. Estos modelos son cruciales en áreas como los motores de búsqueda en internet, los sistemas de gestión documental y las bibliotecas digitales. Permiten a los usuarios encontrar información específica basada en criterios de búsqueda variados. Algunos de los modelos más significativos incluyen el modelo booleano, que utiliza operadores lógicos para la búsqueda; y el modelo vectorial, que emplea conceptos de álgebra vectorial para relacionar los datos con la consulta. \n",
    "\n",
    "Sin pérdida de generalidad, esta clase se centrará en los documentos como datos a recuperar. \n",
    "\n",
    "Formalmente, un MRI es un cuádruplo [D, Q, F, R(aj, di)] donde:\n",
    "* D es un conjunto de representaciones lógicas de los documentos de la colección.\n",
    "* Q es un conjunto compuesto por representaciones lógicas de las necesidades del usuario. Estas representaciones son denominadas consultas.\n",
    "* F es un framework para modelar las representaciones de los documentos, consultas y sus relaciones.\n",
    "* R es una función de ranking que asocia un número real con una consulta q perteneciente a Q y una representación de documento d perteneciente a D. La evaluación de esta función establece un cierto orden entre los documentos de acuerdo a la consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Booleano en la Recuperación de Información\n",
    "\n",
    "El Modelo Booleano se basa en la teoría de conjuntos y el álgebra booleana, proporcionando un marco lógico y matemático para el proceso de búsqueda.\n",
    "\n",
    "### Características Principales\n",
    "\n",
    "- **Presencia de Términos:** Este modelo considera únicamente la presencia o ausencia de términos indexados en los documentos. No se toma en cuenta la frecuencia o el contexto de estos términos.\n",
    "\n",
    "- **Binario en la Indexación:** Los términos indexados se asignan pesos binarios, Wi,j, que pueden ser 0 o 1. Estos representan la ausencia o presencia del término en el documento, respectivamente.\n",
    "\n",
    "- **Estructura de Consulta:** Las consultas se formulan mediante términos indexados, los cuales están interconectados por tres operadores lógicos fundamentales: NOT, AND, OR. Esto permite realizar búsquedas complejas y específicas.\n",
    "\n",
    "- **Expresión Lógica de las Consultas:** Las consultas pueden ser formuladas como una disyunción de conjunciones, conocida como Forma Normal Disyuntiva. Esto permite una mayor flexibilidad y precisión en la definición de los criterios de búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install sympy\n",
    "!python3.10 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import spacy\n",
    "from sympy import sympify, to_dnf, Not, And, Or\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "l.append(4)\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar con el desarollo de MRI, es importante pre-procesar el corpus. Este proceso puede tomar un tiempo considerable, por lo que se sugiere que al culminarlo almacene los resultados en memoria. Para facilitar tal proceso, se recomienda volcar la informacieon en una estructura cómoda: diccionario. Por supuesto, la información que aparezca en el diccionario es la deseada por cada equipo según sus consideraciones. \n",
    "\n",
    "A continuación se brinda funciones auxiliares necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_json(file_path, data):\n",
    "    with open(file_path, \"w\") as archivo_json:\n",
    "        json.dump(mi_diccionario, archivo_json, indent=4)\n",
    "\n",
    "def load_json(file_path): \n",
    "    with open(file_path, 'rb') as fp:\n",
    "        data = json.load(fp)\n",
    "    return data\n",
    "\n",
    "def get_tokens(text):\n",
    "    for token in nlp(text):\n",
    "        if token.is_punct:\n",
    "            pass\n",
    "        else:\n",
    "            yield token.lemma_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando el corpus tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = []     # cargar del json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación vectorial de los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(tokenized_docs)\n",
    "vocabulary = list(dictionary.token2id.keys())\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación de la consulta en FND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a & b) | (a & ~c)\n"
     ]
    }
   ],
   "source": [
    "def query_to_dnf(query):\n",
    "    query = query.lower().replace(\"and\", \"&\").replace(\"or\", \"|\").replace(\"not\", \"~\")\n",
    "\n",
    "    # Procesar la consulta con spaCy\n",
    "    doc = nlp(query)\n",
    "\n",
    "    # Filtrar y procesar tokens\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        # Filtrar manteniendo caracteres alfabéticos y símbolos específicos\n",
    "        if token.text.isalpha() or token.text in ['&', '~', '|', '(', ')']:\n",
    "            tokens.append(token.text)\n",
    "\n",
    "    # Añadir '&' donde sea necesario\n",
    "    processed_tokens = []\n",
    "    for i in range(len(tokens)):\n",
    "        processed_tokens.append(tokens[i])\n",
    "        if i < len(tokens) - 1 and tokens[i] not in ['(', '&', '~', '|'] and tokens[i+1] not in [')', '&', '~', '|']:\n",
    "            processed_tokens.append('&')\n",
    "\n",
    "    # Unir la cadena\n",
    "    processed_query = ' '.join(processed_tokens)\n",
    "\n",
    "    # Convertir a expresión sympy y aplicar to_dnf\n",
    "    query_expr = sympify(processed_query, evaluate=False)\n",
    "    query_dnf = to_dnf(query_expr, simplify=True)\n",
    "\n",
    "    return query_dnf\n",
    "\n",
    "consulta = \"A AND (B OR NOT C)\"\n",
    "consulta_dnf = query_to_dnf(consulta)\n",
    "print(consulta_dnf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la función de peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el marco del modelo booleano, los pesos de los términos indexados se definen de manera binaria, denotados como `W_ij ∈ {0, 1}`. Aquí, una consulta `q` se representa como una expresión booleana convencional. Consideremos `q_fnd` como la Forma Normal Disyuntiva (FND) de la consulta `q`, y `q_ce` como una de las componentes conjuntivas de `q_fnd`.\n",
    "\n",
    "La similitud entre un documento `d_i` y la consulta `q` se define de la siguiente manera:\n",
    "\n",
    "- `sim(d_i, q) = 1` si existe al menos una componente conjuntiva `q_ce` en `q_fnd` tal que para todo término `k` en `q_ce`, la presencia del término en `d_i` es igual a la presencia del término en `q_ce`.\n",
    "- En caso contrario, `sim(d_i, q) = 0`.\n",
    "\n",
    "Esta definición establece una forma clara de medir la similitud entre documentos y consultas en el modelo booleano, basándose en la presencia o ausencia de términos específicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_docs(query_dnf):\n",
    "    global tokenized_docs, dictionary, corpus\n",
    "\n",
    "    # Función para verificar si un documento satisface una componente conjuntiva de la consulta\n",
    "    def satisfies_conjunctive_component(doc_bow, conjunctive_component):\n",
    "        doc_terms = set(dict(doc_bow).keys())\n",
    "        for term in conjunctive_component.args:\n",
    "            term_id = dictionary.token2id.get(term.name, -1)\n",
    "            if isinstance(term, Not):\n",
    "                # Si el término está negado, debe estar ausente en el documento\n",
    "                if term_id in doc_terms:\n",
    "                    return False\n",
    "            else:\n",
    "                # Si el término no está negado, debe estar presente en el documento\n",
    "                if term_id not in doc_terms:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    matching_documents = []\n",
    "    for doc_id, doc_bow in enumerate(corpus):\n",
    "        # Revisar cada componente conjuntiva de la consulta DNF\n",
    "        if isinstance(query_dnf, And) or isinstance(query_dnf, Or):\n",
    "            # Si la consulta DNF tiene múltiples términos\n",
    "            if any(satisfies_conjunctive_component(doc_bow, component) for component in query_dnf.args):\n",
    "                matching_documents.append(doc_id)\n",
    "        else:\n",
    "            # Si la consulta DNF es un solo término o una única conjunción negada\n",
    "            if satisfies_conjunctive_component(doc_bow, query_dnf):\n",
    "                matching_documents.append(doc_id)\n",
    "\n",
    "    return matching_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"     # insertar consulta\n",
    "get_matching_docs(query_to_dnf(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros modelos\n",
    "\n",
    "1. **Modelo Booleano Difuso**: Es una variante del modelo booleano tradicional que introduce grados de pertenencia para los términos en los documentos. En lugar de utilizar valores binarios (0 o 1) para indicar la presencia o ausencia de términos, este modelo asigna valores en el rango de 0 a 1, representando el grado de relevancia o coincidencia de un término en un documento. Esto permite una recuperación más matizada y flexible que el modelo booleano estándar.\n",
    "\n",
    "2. **Modelo Booleano Extendido**: Este modelo expande el modelo booleano clásico al permitir el uso de pesos en los términos de las consultas y en los documentos. Los pesos indican la importancia de un término dentro de una consulta o un documento, permitiendo una recuperación de información más precisa y flexible que el modelo booleano original, que solo considera la presencia o ausencia de términos.\n",
    "\n",
    "3. **Modelo Vector Generalizado**: Es una extensión del modelo vectorial estándar que permite el uso de diferentes funciones de ponderación y similitud. En lugar de limitarse a medidas de similitud coseno típicas del modelo vectorial, el modelo vector generalizado puede incorporar diversas métricas para calcular la similitud entre documentos y consultas, ofreciendo así una mayor flexibilidad y potencialmente una mejora en la precisión de los resultados.\n",
    "\n",
    "4. **Modelo de Indexación de Semántica Latente (LSI, por sus siglas en inglés)**: Este modelo se centra en capturar la relación semántica subyacente entre términos y documentos. Utiliza técnicas de descomposición matricial, como la descomposición en valores singulares, para reducir la dimensionalidad de la matriz término-documento. Al hacerlo, el LSI puede identificar patrones y asociaciones implícitas en el uso de palabras, mejorando la recuperación de información al superar algunas de las limitaciones del análisis de términos puramente sintáctico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
