{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instalando las dependencias ...\n",
        "\n",
        "Durante la clase se estarán utilizando las siguientes bibliotecas:\n",
        "- `opencv-python` para el procesamiento de imágenes.\n",
        "- `pandas` para la manipulación y análisis de datos.\n",
        "- `numpy` para operaciones matemáticas y manejo de matrices.\n",
        "- `matplotlib` para la visualización de datos y gráficos.\n",
        "- `scikit-learn` para el aprendizaje automático y las métricas de evaluación del modelo.\n",
        "\n",
        "Compruebe que tenga las bibliotecas o instálelas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eTQ5UAqYz8v"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn opencv-python pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9d4EgJKZHtC"
      },
      "source": [
        "# Laboratorio #5: Procesamiento de imágenes\n",
        "\n",
        "Los Sistemas de Recuperación de Información se enfrentan a la compleja tarea de trabajar con una variedad de formatos de datos, cada uno con sus propias particularidades. Cuando se trata de datos visuales, como las imágenes, la tarea se vuelve aún más desafiante debido a la naturaleza visual de la información. En este contexto, la extracción de características se vuelve crucial ya que permite a los sistemas describir y representar cada imagen de manera significativa. Mediante la identificación de patrones, colores, formas y texturas relevantes, los sistemas pueden operar con la información extraída para proporcionar respuestas precisas a las consultas de los usuarios.\n",
        "\n",
        "La extracción de características en imágenes no solo permite comprender el contenido visual, sino que también facilita la comparación, análisis y clasificación de imágenes, incluso en conjuntos de datos extensos y diversos. Al encontrar similitudes y relaciones entre imágenes, los sistemas de recuperación de información pueden ofrecer resultados relevantes y útiles a los usuarios. En resumen, la extracción (y selección) de características desempeña un papel fundamental en la mejora de la eficiencia y la precisión de los SRI.\n",
        "\n",
        "El objetivo de la clase práctica es explorar y comparar diversas características extraídas de imágenes con el fin de determinar cuál de ellas es la más efectiva para predecir etiquetas predefinidas.\n",
        "\n",
        "Como ejercicio motivador cuente con:\n",
        "> Se tiene un conjunto de imágenes de Pokemon en un SRI y el desarrollador quiere indexar cada imagen según el tipo de cada criatura. A priori se cuenta con el tipo de cada Pokemon presente en los datos. El problema está en que cada año sale un nuevo juego, conocido como edición, de Pokemon y con ello nuevas criaturas, de las cuales solo se tiene su imagen, hasta que la compañía decida sacar la información de los nuevos Pokemon. Luego, el desarrollador quiere poder catalogar las nuevas imágenes de Pokemon que se pongan en el SRI, con el objetivo de indexarlas y tener su sistema actualizado en todo momento.\n",
        "\n",
        "Para poder resolver el problema anterior es necesario determinar el mejor extractor de características de la imágenes de Pokemon y buscar algún algoritmo que relaciones las características con el tipo de Pokemon. \n",
        "\n",
        "**Los estudiantes se centrarán en el extractor y los profesores en el elgoritmo que establece la relación.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Solución de los profesores\n",
        "from classifier import classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargar las imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_dir = 'dataset/images'\n",
        "filenames = os.listdir(image_dir)\n",
        "\n",
        "# Lista para almacenar las imágenes\n",
        "images = []\n",
        "# Lista para almacenar los nombres de los Pokemon. La posición coincide con `images`\n",
        "names = []\n",
        "\n",
        "for filename in filenames:\n",
        "    names.append(filename[:-4])\n",
        "    # Leer la imagen como un array de NumPy\n",
        "    image = cv2.imread(os.path.join(image_dir, filename))\n",
        "    \n",
        "    # Agregar la imagen a la lista\n",
        "    images.append(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargar las etiquetas de cada Pokemon. Existen Pokemon que son de 2 tipos a la vez, para el ejercicio solo se considerará el tipo predominante el cual se encuentra en la columna `Type1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Especifica la ruta del archivo CSV\n",
        "file_path = 'dataset/pokemon.csv'\n",
        "\n",
        "# Carga el archivo CSV en un DataFrame de pandas\n",
        "dataframe = pd.read_csv(file_path)\n",
        "\n",
        "# Muestra las primeras filas del DataFrame para verificar que se haya cargado correctamente\n",
        "print(dataframe[:10])\n",
        "\n",
        "# Establece la columna 'Name' como índice al ser todos los valores únicos\n",
        "dataframe.set_index('Name', inplace=True)\n",
        "\n",
        "# Obtiene las etiquetas del tipo de cada Pokemon\n",
        "labels = dataframe['Type1'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mostremos una foto aleatoria del conjunto de los datos, junto al nombre y tipo del Pokemon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar una foto del dataset\n",
        "\n",
        "# Seleccionar una posición aleatoria correspondiente a una imagen de Pokemon \n",
        "pos = random.randint(0, len(images) - 1)\n",
        "\n",
        "# Mostrar la imagen\n",
        "plt.imshow(images[pos])\n",
        "\n",
        "# Desactivar los ejes\n",
        "plt.axis('off')\n",
        "\n",
        "# Agregar el nombre y tipo de la imagen como leyenda\n",
        "plt.text(10, 10, f\"{names[pos]}\\n({dataframe.loc[names[pos]]['Type1']})\", fontsize=14, color='white', backgroundcolor='black', alpha=1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comencemos a implementar los extractores de características.\n",
        "\n",
        "## Escala de grises\n",
        "\n",
        "La escala de grises de una imagen es una representación en la que cada píxel de la imagen se muestra con un solo valor de intensidad luminosa, en lugar de una combinación de colores. En otras palabras, es una imagen en blanco y negro que contiene tonos de gris que varían desde el negro más oscuro hasta el blanco más claro.\n",
        "\n",
        "Puede utilizar la función `cv2.cvtColor/2`, la cual recibe la imagen y el flag `cv2.COLOR_BGR2GRAY` para indicar el cambio de la representación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def grayscale_feature_extractor(image):\n",
        "    \"\"\"\n",
        "    Convert an image to grayscale\n",
        "    \n",
        "    Arg:\n",
        "        -image (numpy.ndarray) : Image.\n",
        "        \n",
        "    Return:\n",
        "        - numpy.ndarray\n",
        "    \n",
        "    \"\"\"\n",
        "    raise Exception(\"Not implemented\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprobando este extractor para solucionar el problema inicial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grayscale_knn = classifier('KNN', grayscale_feature_extractor, images, labels)\n",
        "print('Model: KNN', '\\nExtractor: grayscale', f'\\nMetrics: {grayscale_knn}')\n",
        "\n",
        "grayscale_svc = classifier('SVM', grayscale_feature_extractor, images, labels)\n",
        "print('Model: SVM', '\\nExtractor: grayscale', f'\\nMetrics: {grayscale_svc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------\n",
        "\n",
        "## HSV (Matiz, Saturación, Valor)\n",
        "\n",
        "Representa un modelo de color que describe cómo se perciben y se manipulan los colores en las imágenes. A diferencia del modelo RGB (Rojo, Verde, Azul), que se basa en la combinación de diferentes intensidades de luz en tres canales de color, el modelo HSV se centra en cómo los humanos perciben y describen los colores.\n",
        "\n",
        "Es muy útil porque separa la información del color, la intensidad y la saturación.\n",
        "\n",
        "Puede utilizar la función `cv2.cvtColor/2`, la cual recibe la imagen y el flag `cv2.COLOR_BGR2HSV` para indicar el cambio de la representación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hsv_feature_extractor(image):\n",
        "    \"\"\"\n",
        "    Convert an image to hsv scale\n",
        "    \n",
        "    Arg:\n",
        "        -image (numpy.ndarray) : Image.\n",
        "        \n",
        "    Return:\n",
        "        - numpy.ndarray\n",
        "        \n",
        "    \"\"\"\n",
        "    raise Exception(\"Not implemented\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprobando este extractor para solucionar el problema inicial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hsv_knn = classifier('KNN', hsv_feature_extractor, images, labels)\n",
        "print('Model: KNN', '\\nExtractor: hsv', f'\\nMetrics: {hsv_knn}')\n",
        "\n",
        "print('--------------\\n')\n",
        "\n",
        "hsv_svc = classifier('SVM', hsv_feature_extractor, images, labels)\n",
        "print('Model: SVM', '\\nExtractor: hsv', f'\\nMetrics: {hsv_svc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------\n",
        "\n",
        "## Histograma\n",
        "\n",
        "Representación gráfica de la distribución de los valores de intensidad de los píxeles en la imagen, o sea, muestra la frecuencia con la que aparecen diferentes niveles de intensidad en la imagen.\n",
        "\n",
        "Puede utilizar la función `cv2.calcHist/5`, la cual recibe una imagen y un conjunto de parámetros que pueden poner por defecto los siguientes: `[0], None, [256], [0, 256]`. El orden indica lo siguiente:\n",
        "- Canal del color de la imagen. Una imagen en escala de grises solo tiene un canal (0), en escala RGB existen 3 canales, uno por cada color.\n",
        "- Región de la imagen a utilizar. `None` indica toda la imagen.\n",
        "- La cantidad de contenedores para agrupar los píxeles con intensidad $k$. El número $256$ indica el total de valores distintos que puede tener cada pixel.\n",
        "- Rango de intensidad que puede tomar cada pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def histogram_feature_extractor(image):\n",
        "    \"\"\"\n",
        "    Get the histogram of an image\n",
        "    \n",
        "    Arg:\n",
        "        -image (numpy.ndarray) : Image.\n",
        "        \n",
        "    Return:\n",
        "        - numpy.ndarray\n",
        "    \n",
        "    \"\"\"\n",
        "    raise Exception(\"Not implemented\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprobando este extractor para solucionar el problema inicial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "histogram_knn = classifier('KNN', histogram_feature_extractor, images, labels)\n",
        "print('Model: KNN', '\\nExtractor: histogram', f'\\nMetrics: {histogram_knn}')\n",
        "\n",
        "print('--------------\\n')\n",
        "\n",
        "histogram_svc = classifier('SVM', histogram_feature_extractor, images, labels)\n",
        "print('Model: SVM', '\\nExtractor: histogram', f'\\nMetrics: {histogram_svc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------\n",
        "\n",
        "## Color promedio\n",
        "\n",
        "Calcula el promedio del los colores dentro de un bloque de una imagen. Se considera un bloque a una región rectangular o cuadrada dentro de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dominant_color_feature_extractor(image, block_size):\n",
        "    \"\"\"\n",
        "    Calculates the average color per block of an image\n",
        "    \n",
        "    Args: \n",
        "        - image (numpy.ndarray) : Image.\n",
        "        - block_size (int) : Size (height and width) of the block.\n",
        "        \n",
        "    Return:\n",
        "        - numpy.ndarray\n",
        "    \n",
        "    \"\"\"\n",
        "    raise Exception(\"Not implemented\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprobando este extractor para solucionar el problema inicial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frame_size = 30\n",
        "\n",
        "dominant_color_knn = classifier(\n",
        "    'KNN', \n",
        "    lambda x: dominant_color_feature_extractor(x, frame_size),\n",
        "    images, \n",
        "    labels\n",
        ")\n",
        "print('Model: KNN', '\\nExtractor: dominant_color', f'\\nMetrics: {dominant_color_knn}')\n",
        "\n",
        "print('--------------\\n')\n",
        "\n",
        "dominant_color_svc = classifier(\n",
        "    'SVM', \n",
        "    lambda x: dominant_color_feature_extractor(x, frame_size),\n",
        "    images, \n",
        "    labels\n",
        ")\n",
        "print('Model: SVM', '\\nExtractor: dominant_color', f'\\nMetrics: {dominant_color_svc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------\n",
        "\n",
        "Prueba extra. Veamos cómo se comparta si se trabaja con la imagen sin extraer ningún tipo de información. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "without_changes_knn = classifier(\n",
        "    'KNN', \n",
        "    lambda x: x,\n",
        "    images, \n",
        "    labels\n",
        ")\n",
        "print('Model: KNN', '\\nExtractor: without changes', f'\\nMetrics: {without_changes_knn}')\n",
        "\n",
        "print('--------------\\n')\n",
        "\n",
        "without_changes_svc = classifier(\n",
        "    'SVM', \n",
        "    lambda x: x,\n",
        "    images, \n",
        "    labels\n",
        ")\n",
        "print('Model: SVM', '\\nExtractor: without changes', f'\\nMetrics: {without_changes_svc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los resultados tan malos pueden deberse a una(s) de las siguientes causas: \n",
        "- El conjunto de datos no tiene datos suficientes como para que el algoritmo capture las características comunes de los Pokemon de un mismo tipo, afectando a la predicción de un Pokemon desconocido.\n",
        "- Los extractores de características usados no son los idóneos para capturar la información relevante de cada imagen.\n",
        "- Los algoritmos utilizados para captar las relaciones entre las imágenes (Pokemon) y el tipo no son los correctos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
