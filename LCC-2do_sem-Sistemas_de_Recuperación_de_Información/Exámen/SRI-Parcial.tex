
\documentclass[10pt]{exam}

\usepackage[top=0.5in, bottom=1in, left=0.7in, right=0.7in]{geometry}

\usepackage{multicol}
\usepackage{graphicx}
\usepackage{enumitem}

%\usepackage{xcolor}

\pagestyle{empty}

\setlength{\columnsep}{20pt}
\renewcommand{\choicelabel}{\alph{choice})}
%\raggedright

\usepackage{tikz}
\usepackage{qrcode}

\makeatletter
\renewenvironment{choices}
{\list{\choicelabel}
    {\usecounter{choice}\def\makelabel##1{\hss\llap{##1}}%
        \setlength{\leftmargin}{15pt}
        \def\choice{
            \if@correctchoice
            \color@endgroup
            \endgroup
            \fi
            \item
            \do@choice@pageinfo
        } 
        \def\CorrectChoice{
            \if@correctchoice
            \color@endgroup
            \endgroup
            \fi
            \ifprintanswers
            \ifhmode \unskip\unskip\unvbox\voidb@x \fi
            \begingroup \color@begingroup \@correctchoicetrue
            \CorrectChoice@Emphasis
            \fi
            \item
            \do@choice@pageinfo
        } 
        \let\correctchoice\CorrectChoice
        \labelwidth\leftmargin\advance\labelwidth-\labelsep
        \topsep=0pt
        \partopsep=0pt
        \choiceshook
    }
}
{\if@correctchoice \color@endgroup \endgroup \fi \endlist}
\makeatother


\newcommand{\encabezado}[3]{
    
    \begin{minipage}[c]{0.55\textwidth}
        \begin{centering}
            Trabajo de Control \\
            Sistemas de Recuperación de Información \\
            %Facultad de Matemática y Computación. UH \\
            Fecha: #1 \\
            Temario \##3
            
        \end{centering}
 
    \end{minipage}%
    \begin{minipage}[c]{0.35\textwidth}
        \begin{centering}
            \begin{tikzpicture}
                \node[anchor=north east, inner sep=0pt] at (current page.north east) {\qrcode{#2}};
            \end{tikzpicture}
            
        \end{centering}
    \end{minipage}
    
    \vspace{1\baselineskip}
  
    Nombre: \underline{\hspace{10cm}}  
    Grupo: \underline{\hspace{2cm}} 
        
    \vspace{1\baselineskip}
    Seleccione en cada caso la(s) respuesta(s) correcta(s). Considere también no marcar ninguna opción.
}

\begin{document}
    
    \color{blue}
     
    \encabezado{15 de julio de 2024}{1: [True, False, False, False]\\2: [True, False, True, False]\\3: [True, False, False, False]\\4: [False, False, False, True]\\5: [True, False, False, False]\\6: [False, False, True, False]\\7: [False, True, False, False]\\8: [False, True, False, False]\\9: [False, True, True, False]\\10: [True, True, True, False]\\11: [False, True, False, False]\\12: [True, False, False, False]\\13: [True, False, True, True]\\14: [True, False, False, False]\\15: [False, False, True, False]\\16: [True, True, False, False]\\17: [True, True, False, False]\\18: [False, True, False, False]\\19: [False, False, False, True]\\20: [False, True, False, False]\\}{1}
\begin{questions}
\begin{multicols}{2}

\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, True, True]\\2: [False, True, False, False]\\3: [True, True, False, False]\\4: [True, False, False, False]\\5: [False, True, False, False]\\6: [False, True, False, True]\\7: [False, True, False, False]\\8: [True, False, False, True]\\9: [True, True, False, False]\\10: [False, True, False, False]\\11: [False, False, True, False]\\12: [False, False, False, True]\\13: [True, False, False, False]\\14: [False, False, True, False]\\15: [False, False, False, False]\\16: [False, False, True, False]\\17: [False, True, True, True]\\18: [True, False, False, False]\\19: [True, True, True, False]\\20: [False, False, False, True]\\}{2}
\begin{questions}
\begin{multicols}{2}

\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, False]\\2: [False, True, True, True]\\3: [True, True, True, True]\\4: [True, True, False, True]\\5: [True, True, False, False]\\6: [False, False, True, False]\\7: [False, True, False, True]\\8: [False, True, False, True]\\9: [False, False, False, False]\\10: [False, True, False, False]\\11: [False, False, False, False]\\12: [False, False, False, True]\\13: [False, False, True, False]\\14: [False, True, False, False]\\15: [True, False, False, False]\\16: [True, False, False, False]\\17: [False, False, True, False]\\18: [False, False, False, True]\\19: [True, True, False, True]\\20: [True, False, False, False]\\}{3}
\begin{questions}
\begin{multicols}{2}

\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, True, False]\\2: [False, False, True, False]\\3: [True, True, False, False]\\4: [True, True, False, True]\\5: [False, False, False, True]\\6: [False, True, True, False]\\7: [False, True, False, False]\\8: [True, True, False, True]\\9: [True, True, False, True]\\10: [False, False, False, True]\\11: [False, True, False, False]\\12: [False, False, True, False]\\13: [False, True, False, False]\\14: [False, False, False, True]\\15: [False, True, False, True]\\16: [False, True, True, True]\\17: [True, True, False, False]\\18: [True, False, False, True]\\19: [False, True, True, True]\\20: [False, True, False, False]\\}{4}
\begin{questions}
\begin{multicols}{2}

\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [False, False, True, False]\\3: [False, True, False, True]\\4: [True, False, False, False]\\5: [True, True, True, True]\\6: [False, False, False, True]\\7: [False, True, False, False]\\8: [False, True, True, False]\\9: [False, False, False, True]\\10: [True, True, False, False]\\11: [True, True, False, True]\\12: [False, True, True, True]\\13: [False, False, False, True]\\14: [True, False, False, True]\\15: [False, True, False, False]\\16: [True, False, False, False]\\17: [True, True, True, False]\\18: [False, False, True, False]\\19: [False, True, False, False]\\20: [False, False, True, True]\\}{5}
\begin{questions}
\begin{multicols}{2}

\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, False, True, True]\\3: [False, False, False, True]\\4: [False, True, True, True]\\5: [True, True, True, False]\\6: [True, True, False, True]\\7: [False, True, False, False]\\8: [True, True, True, True]\\9: [False, True, True, True]\\10: [False, True, False, False]\\11: [False, False, True, False]\\12: [False, True, False, True]\\13: [True, False, False, False]\\14: [False, True, False, False]\\15: [True, False, False, False]\\16: [False, False, True, False]\\17: [True, True, False, True]\\18: [False, False, False, True]\\19: [True, False, False, True]\\20: [True, True, False, False]\\}{6}
\begin{questions}
\begin{multicols}{2}

\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, True, True]\\2: [True, True, False, False]\\3: [True, False, False, False]\\4: [False, False, False, False]\\5: [False, True, False, False]\\6: [False, False, True, False]\\7: [False, False, True, False]\\8: [False, False, True, False]\\9: [False, False, True, False]\\10: [False, True, False, False]\\11: [True, True, False, True]\\12: [False, False, False, True]\\13: [False, False, True, False]\\14: [True, True, False, True]\\15: [True, True, True, False]\\16: [True, True, False, True]\\17: [False, False, True, False]\\18: [False, False, False, False]\\19: [False, False, True, True]\\20: [True, False, False, False]\\}{7}
\begin{questions}
\begin{multicols}{2}

\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, True]\\2: [True, True, True, False]\\3: [False, False, True, False]\\4: [True, True, False, True]\\5: [True, False, False, True]\\6: [True, True, False, True]\\7: [False, False, False, True]\\8: [False, False, True, False]\\9: [False, False, True, False]\\10: [True, False, False, False]\\11: [True, True, False, True]\\12: [False, True, False, False]\\13: [False, False, True, False]\\14: [False, False, False, True]\\15: [False, True, True, False]\\16: [False, False, False, True]\\17: [False, False, True, False]\\18: [False, True, False, False]\\19: [True, False, False, False]\\20: [False, False, True, True]\\}{8}
\begin{questions}
\begin{multicols}{2}

\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, False]\\2: [False, False, False, False]\\3: [False, False, True, True]\\4: [False, True, True, True]\\5: [True, False, False, False]\\6: [False, False, False, False]\\7: [True, False, True, False]\\8: [True, True, False, True]\\9: [False, False, True, False]\\10: [False, False, False, True]\\11: [True, True, False, False]\\12: [False, True, False, False]\\13: [True, True, True, False]\\14: [False, True, False, False]\\15: [False, False, True, False]\\16: [False, True, True, True]\\17: [False, True, False, False]\\18: [True, True, False, False]\\19: [False, False, True, False]\\20: [True, False, False, True]\\}{9}
\begin{questions}
\begin{multicols}{2}

\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, False, True]\\2: [False, False, True, False]\\3: [False, True, False, False]\\4: [True, True, True, False]\\5: [False, True, False, False]\\6: [True, False, False, True]\\7: [False, False, True, False]\\8: [False, True, False, True]\\9: [True, True, False, False]\\10: [False, True, True, False]\\11: [True, False, False, False]\\12: [False, True, False, False]\\13: [True, True, True, False]\\14: [False, False, False, True]\\15: [False, False, True, False]\\16: [False, False, True, True]\\17: [False, False, False, True]\\18: [True, False, False, False]\\19: [True, True, True, True]\\20: [True, True, False, True]\\}{10}
\begin{questions}
\begin{multicols}{2}

\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, True, True]\\2: [False, True, False, False]\\3: [False, True, False, False]\\4: [False, False, False, True]\\5: [False, True, True, True]\\6: [True, False, False, False]\\7: [False, True, True, True]\\8: [False, False, True, False]\\9: [True, True, False, True]\\10: [True, True, False, False]\\11: [False, True, False, True]\\12: [False, True, False, False]\\13: [False, True, False, False]\\14: [False, False, False, True]\\15: [False, True, False, True]\\16: [False, True, False, False]\\17: [True, True, False, False]\\18: [False, True, False, False]\\19: [False, False, True, False]\\20: [False, False, True, True]\\}{11}
\begin{questions}
\begin{multicols}{2}

\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [True, True, False, False]\\3: [False, True, False, False]\\4: [True, False, True, True]\\5: [False, True, False, False]\\6: [False, False, True, True]\\7: [False, False, True, False]\\8: [True, False, False, True]\\9: [False, True, False, False]\\10: [False, False, True, True]\\11: [True, True, True, True]\\12: [False, False, False, True]\\13: [False, True, True, True]\\14: [True, False, False, False]\\15: [True, False, False, False]\\16: [False, False, False, True]\\17: [False, True, True, False]\\18: [True, False, False, False]\\19: [False, False, False, True]\\20: [False, False, False, True]\\}{12}
\begin{questions}
\begin{multicols}{2}

\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, True, True, True]\\3: [True, True, False, True]\\4: [False, True, False, False]\\5: [False, False, True, False]\\6: [False, False, False, True]\\7: [False, False, False, True]\\8: [False, False, True, False]\\9: [False, False, True, False]\\10: [False, True, False, True]\\11: [False, False, False, True]\\12: [True, True, True, True]\\13: [False, False, False, False]\\14: [True, False, False, False]\\15: [True, False, False, False]\\16: [False, False, False, True]\\17: [False, True, False, False]\\18: [True, True, False, False]\\19: [False, False, True, True]\\20: [False, True, False, True]\\}{13}
\begin{questions}
\begin{multicols}{2}

\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [True, False, False, False]\\3: [True, True, True, False]\\4: [False, True, False, True]\\5: [True, True, True, True]\\6: [False, False, False, True]\\7: [False, False, True, False]\\8: [True, True, False, True]\\9: [False, False, True, False]\\10: [False, True, True, False]\\11: [False, False, True, False]\\12: [False, True, False, False]\\13: [False, True, False, True]\\14: [False, False, True, False]\\15: [False, False, True, True]\\16: [False, False, True, True]\\17: [True, False, False, False]\\18: [True, True, False, False]\\19: [False, False, False, True]\\20: [False, False, True, False]\\}{14}
\begin{questions}
\begin{multicols}{2}

\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, True, True]\\2: [False, True, False, False]\\3: [False, False, False, False]\\4: [False, False, True, True]\\5: [False, True, True, False]\\6: [False, False, False, True]\\7: [True, False, False, False]\\8: [False, False, False, False]\\9: [False, False, False, True]\\10: [True, False, False, False]\\11: [False, True, True, True]\\12: [False, False, False, False]\\13: [True, False, False, False]\\14: [True, True, False, False]\\15: [True, False, False, False]\\16: [True, False, False, False]\\17: [True, True, True, False]\\18: [True, True, False, True]\\19: [True, False, True, False]\\20: [True, True, True, True]\\}{15}
\begin{questions}
\begin{multicols}{2}

\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, True]\\2: [True, True, True, True]\\3: [True, False, False, False]\\4: [True, False, True, True]\\5: [False, False, True, False]\\6: [False, False, True, False]\\7: [False, True, True, True]\\8: [False, True, False, False]\\9: [False, False, False, False]\\10: [False, False, False, False]\\11: [False, False, True, True]\\12: [False, False, True, False]\\13: [True, False, False, True]\\14: [False, False, True, False]\\15: [False, True, False, False]\\16: [False, False, True, True]\\17: [False, False, False, True]\\18: [True, True, False, False]\\19: [False, False, True, False]\\20: [True, True, True, True]\\}{16}
\begin{questions}
\begin{multicols}{2}

\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, False]\\2: [True, True, False, True]\\3: [False, False, False, True]\\4: [False, True, True, True]\\5: [False, True, False, False]\\6: [False, True, False, False]\\7: [False, True, True, False]\\8: [False, False, False, False]\\9: [True, True, True, True]\\10: [False, True, False, False]\\11: [True, True, False, True]\\12: [True, True, False, False]\\13: [False, True, True, True]\\14: [False, True, False, False]\\15: [False, False, True, False]\\16: [False, True, True, True]\\17: [True, False, False, False]\\18: [True, False, False, False]\\19: [True, True, True, False]\\20: [False, True, True, False]\\}{17}
\begin{questions}
\begin{multicols}{2}

\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, True, True, True]\\3: [False, True, True, False]\\4: [False, True, False, False]\\5: [False, True, True, True]\\6: [False, False, True, False]\\7: [True, False, False, False]\\8: [False, True, False, False]\\9: [False, False, False, True]\\10: [False, False, True, False]\\11: [True, False, False, True]\\12: [True, True, False, False]\\13: [False, False, True, False]\\14: [True, True, True, True]\\15: [True, True, True, True]\\16: [False, True, False, True]\\17: [False, True, False, False]\\18: [False, True, False, True]\\19: [False, True, False, False]\\20: [False, False, True, False]\\}{18}
\begin{questions}
\begin{multicols}{2}

\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, False]\\2: [True, True, True, True]\\3: [False, True, False, False]\\4: [False, False, False, True]\\5: [False, True, False, False]\\6: [False, True, False, False]\\7: [False, False, True, False]\\8: [True, True, False, True]\\9: [True, False, False, False]\\10: [False, True, False, False]\\11: [False, False, True, True]\\12: [False, False, False, True]\\13: [True, False, False, False]\\14: [False, True, True, True]\\15: [False, False, False, False]\\16: [False, False, True, True]\\17: [False, True, False, False]\\18: [False, True, False, True]\\19: [True, False, True, True]\\20: [False, False, False, True]\\}{19}
\begin{questions}
\begin{multicols}{2}

\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [False, True, True, True]\\3: [False, True, False, True]\\4: [True, True, False, True]\\5: [False, False, True, False]\\6: [True, False, False, True]\\7: [False, True, True, False]\\8: [False, True, True, True]\\9: [False, False, True, False]\\10: [True, False, False, False]\\11: [True, False, False, False]\\12: [True, False, False, False]\\13: [False, False, True, True]\\14: [False, True, False, False]\\15: [False, False, True, False]\\16: [True, True, True, False]\\17: [False, True, False, False]\\18: [True, False, False, False]\\19: [False, False, True, False]\\20: [False, False, False, True]\\}{20}
\begin{questions}
\begin{multicols}{2}

\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [True, True, False, False]\\3: [True, True, False, False]\\4: [False, False, True, False]\\5: [False, True, False, True]\\6: [False, True, False, False]\\7: [True, True, False, True]\\8: [False, False, False, True]\\9: [True, True, True, False]\\10: [False, True, False, True]\\11: [False, False, True, True]\\12: [True, False, False, False]\\13: [False, False, False, True]\\14: [False, True, False, False]\\15: [False, True, False, False]\\16: [False, True, False, False]\\17: [False, False, True, False]\\18: [False, True, False, False]\\19: [True, True, True, True]\\20: [False, False, True, True]\\}{21}
\begin{questions}
\begin{multicols}{2}

\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, True, True, False]\\3: [True, True, False, True]\\4: [False, False, False, True]\\5: [False, False, True, False]\\6: [False, True, False, False]\\7: [True, True, True, False]\\8: [False, True, False, False]\\9: [False, True, True, True]\\10: [True, False, False, False]\\11: [True, False, False, False]\\12: [False, True, True, True]\\13: [True, True, False, True]\\14: [False, False, True, False]\\15: [False, False, True, False]\\16: [True, True, False, False]\\17: [False, False, False, True]\\18: [True, False, False, False]\\19: [True, True, False, True]\\20: [False, True, False, False]\\}{22}
\begin{questions}
\begin{multicols}{2}

\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, True]\\2: [False, False, False, False]\\3: [True, True, True, False]\\4: [False, True, False, False]\\5: [True, True, False, True]\\6: [False, True, False, False]\\7: [True, False, False, False]\\8: [True, True, True, True]\\9: [False, False, True, True]\\10: [False, True, False, False]\\11: [True, False, False, False]\\12: [True, True, False, False]\\13: [False, False, True, True]\\14: [True, False, False, False]\\15: [True, False, False, False]\\16: [False, False, True, False]\\17: [False, True, False, True]\\18: [True, False, True, True]\\19: [True, True, False, False]\\20: [False, False, False, True]\\}{23}
\begin{questions}
\begin{multicols}{2}

\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [False, True, True, True]\\3: [False, False, False, False]\\4: [True, False, True, True]\\5: [False, True, False, False]\\6: [False, False, True, False]\\7: [True, True, False, True]\\8: [True, True, False, False]\\9: [False, False, False, True]\\10: [False, False, True, False]\\11: [False, False, False, True]\\12: [True, True, True, False]\\13: [False, False, False, True]\\14: [True, False, False, False]\\15: [False, True, False, False]\\16: [False, True, False, False]\\17: [True, False, True, False]\\18: [True, False, False, True]\\19: [False, True, False, False]\\20: [False, True, True, True]\\}{24}
\begin{questions}
\begin{multicols}{2}

\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, True, False]\\2: [False, True, False, False]\\3: [True, False, False, False]\\4: [False, False, False, True]\\5: [True, False, True, False]\\6: [True, True, False, True]\\7: [False, True, True, True]\\8: [True, False, False, False]\\9: [True, False, False, False]\\10: [False, True, False, True]\\11: [False, False, False, True]\\12: [True, True, False, True]\\13: [False, False, True, False]\\14: [True, True, False, False]\\15: [False, False, False, True]\\16: [True, False, False, True]\\17: [False, False, True, True]\\18: [False, False, False, True]\\19: [False, True, True, True]\\20: [False, False, True, True]\\}{25}
\begin{questions}
\begin{multicols}{2}

\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, False, True, False]\\3: [True, True, False, True]\\4: [False, False, True, False]\\5: [False, True, False, True]\\6: [False, True, True, False]\\7: [False, True, True, False]\\8: [False, False, True, False]\\9: [False, False, True, False]\\10: [False, False, False, False]\\11: [False, True, False, False]\\12: [False, True, False, False]\\13: [True, True, False, False]\\14: [False, False, False, True]\\15: [False, False, False, True]\\16: [False, False, False, True]\\17: [True, True, False, False]\\18: [True, True, False, True]\\19: [False, False, False, True]\\20: [False, False, False, True]\\}{26}
\begin{questions}
\begin{multicols}{2}

\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [True, False, False, False]\\3: [True, True, False, True]\\4: [False, False, True, True]\\5: [False, False, False, False]\\6: [False, True, False, True]\\7: [True, False, False, False]\\8: [False, False, False, True]\\9: [False, False, True, False]\\10: [True, True, False, True]\\11: [True, False, False, False]\\12: [False, False, False, True]\\13: [True, True, False, True]\\14: [False, False, True, False]\\15: [False, True, False, False]\\16: [False, False, False, False]\\17: [False, False, False, True]\\18: [False, False, True, False]\\19: [True, False, False, True]\\20: [False, False, False, True]\\}{27}
\begin{questions}
\begin{multicols}{2}

\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [False, False, True, False]\\3: [False, True, False, False]\\4: [False, True, False, True]\\5: [False, False, False, False]\\6: [False, False, False, False]\\7: [False, True, True, False]\\8: [True, False, False, False]\\9: [False, False, True, False]\\10: [False, False, False, False]\\11: [False, False, True, True]\\12: [False, False, True, False]\\13: [False, False, True, True]\\14: [True, False, False, False]\\15: [True, False, False, False]\\16: [False, True, True, False]\\17: [False, False, True, False]\\18: [False, True, False, False]\\19: [True, True, False, True]\\20: [False, False, False, True]\\}{28}
\begin{questions}
\begin{multicols}{2}

\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [True, True, False, False]\\3: [False, False, True, False]\\4: [True, False, False, False]\\5: [True, True, False, True]\\6: [False, False, True, False]\\7: [True, False, False, False]\\8: [False, False, True, False]\\9: [False, True, True, False]\\10: [False, False, False, False]\\11: [False, False, True, False]\\12: [True, False, True, False]\\13: [True, True, False, False]\\14: [False, False, False, False]\\15: [True, False, False, True]\\16: [True, True, False, True]\\17: [False, False, False, True]\\18: [False, True, True, False]\\19: [True, False, False, False]\\20: [False, False, False, True]\\}{29}
\begin{questions}
\begin{multicols}{2}

\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, True]\\2: [False, False, True, False]\\3: [True, True, False, True]\\4: [True, True, True, True]\\5: [False, True, False, True]\\6: [False, False, False, True]\\7: [False, False, False, True]\\8: [False, False, True, True]\\9: [True, False, False, False]\\10: [True, False, False, False]\\11: [True, True, False, False]\\12: [False, True, False, True]\\13: [True, True, True, False]\\14: [False, False, False, True]\\15: [False, True, True, False]\\16: [True, True, False, True]\\17: [False, True, False, False]\\18: [True, False, False, False]\\19: [True, False, False, False]\\20: [False, False, True, False]\\}{30}
\begin{questions}
\begin{multicols}{2}

\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, True, True]\\2: [False, False, True, False]\\3: [False, True, False, True]\\4: [False, True, False, False]\\5: [True, False, False, True]\\6: [False, True, False, False]\\7: [False, False, True, False]\\8: [False, True, False, False]\\9: [False, False, True, True]\\10: [True, False, False, False]\\11: [False, False, False, False]\\12: [True, True, False, True]\\13: [True, True, False, True]\\14: [True, True, True, True]\\15: [True, False, False, False]\\16: [False, False, False, True]\\17: [True, False, False, False]\\18: [False, False, False, True]\\19: [False, True, False, False]\\20: [True, False, False, False]\\}{31}
\begin{questions}
\begin{multicols}{2}

\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [False, True, False, True]\\3: [False, True, True, True]\\4: [True, False, True, False]\\5: [False, True, True, False]\\6: [False, False, False, True]\\7: [False, False, True, False]\\8: [False, False, False, True]\\9: [True, False, False, False]\\10: [True, True, True, False]\\11: [False, True, False, True]\\12: [True, False, False, False]\\13: [False, False, False, True]\\14: [False, True, False, False]\\15: [False, True, False, False]\\16: [True, True, False, False]\\17: [False, True, False, False]\\18: [True, True, False, True]\\19: [False, False, True, False]\\20: [False, True, False, False]\\}{32}
\begin{questions}
\begin{multicols}{2}

\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [False, True, True, True]\\3: [True, False, False, False]\\4: [False, True, False, False]\\5: [False, True, False, False]\\6: [False, True, False, True]\\7: [False, False, True, True]\\8: [False, False, False, True]\\9: [False, False, True, True]\\10: [True, False, False, False]\\11: [True, False, False, False]\\12: [True, False, False, True]\\13: [True, True, False, True]\\14: [True, True, False, False]\\15: [False, True, True, True]\\16: [False, True, False, False]\\17: [False, True, False, True]\\18: [False, True, True, False]\\19: [False, False, True, False]\\20: [True, False, False, False]\\}{33}
\begin{questions}
\begin{multicols}{2}

\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, False]\\2: [False, False, False, False]\\3: [True, False, False, False]\\4: [True, True, True, True]\\5: [False, False, True, True]\\6: [False, False, False, False]\\7: [False, False, True, False]\\8: [False, True, False, True]\\9: [False, False, True, False]\\10: [False, False, False, True]\\11: [False, False, True, False]\\12: [False, True, False, False]\\13: [True, False, False, True]\\14: [True, True, False, True]\\15: [False, True, False, False]\\16: [True, True, False, False]\\17: [True, False, True, False]\\18: [False, True, False, False]\\19: [False, False, True, False]\\20: [False, True, False, True]\\}{34}
\begin{questions}
\begin{multicols}{2}

\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, True, False, False]\\3: [False, True, True, True]\\4: [False, False, True, False]\\5: [True, True, False, True]\\6: [False, False, False, True]\\7: [True, True, False, False]\\8: [True, False, False, False]\\9: [False, True, True, False]\\10: [False, True, False, True]\\11: [False, True, False, False]\\12: [False, False, True, False]\\13: [True, True, False, False]\\14: [False, False, True, False]\\15: [False, True, False, True]\\16: [True, False, True, False]\\17: [False, True, True, False]\\18: [False, False, False, True]\\19: [False, False, True, False]\\20: [True, False, False, True]\\}{35}
\begin{questions}
\begin{multicols}{2}

\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [False, False, False, True]\\3: [False, True, False, False]\\4: [False, False, True, False]\\5: [False, False, False, True]\\6: [False, False, True, False]\\7: [False, False, False, True]\\8: [False, True, True, True]\\9: [False, False, False, False]\\10: [False, False, False, True]\\11: [True, True, False, True]\\12: [False, False, True, True]\\13: [True, False, False, False]\\14: [True, True, False, True]\\15: [False, False, True, False]\\16: [True, False, True, False]\\17: [False, True, False, False]\\18: [False, True, False, False]\\19: [False, True, True, True]\\20: [False, False, False, False]\\}{36}
\begin{questions}
\begin{multicols}{2}

\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, True, False]\\2: [True, True, False, False]\\3: [True, False, False, False]\\4: [False, True, False, False]\\5: [True, False, False, False]\\6: [True, False, False, True]\\7: [False, False, True, True]\\8: [False, True, True, True]\\9: [True, False, False, False]\\10: [True, True, False, False]\\11: [False, True, False, False]\\12: [False, False, False, True]\\13: [False, True, False, False]\\14: [True, False, False, False]\\15: [False, False, True, False]\\16: [False, False, False, True]\\17: [True, False, False, False]\\18: [False, False, False, True]\\19: [False, False, False, True]\\20: [True, True, False, True]\\}{37}
\begin{questions}
\begin{multicols}{2}

\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, True, True, True]\\3: [False, False, False, False]\\4: [False, False, True, False]\\5: [False, False, False, True]\\6: [False, False, True, False]\\7: [False, False, True, False]\\8: [True, True, True, True]\\9: [True, True, True, False]\\10: [True, False, False, True]\\11: [True, True, False, True]\\12: [False, True, False, False]\\13: [False, True, False, False]\\14: [True, False, False, False]\\15: [False, True, True, True]\\16: [False, False, True, False]\\17: [False, False, False, True]\\18: [True, False, False, False]\\19: [False, True, False, False]\\20: [True, False, False, False]\\}{38}
\begin{questions}
\begin{multicols}{2}

\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [False, True, True, True]\\3: [False, False, True, True]\\4: [False, False, False, True]\\5: [False, True, False, True]\\6: [False, True, False, True]\\7: [True, True, False, False]\\8: [True, True, False, False]\\9: [True, False, False, False]\\10: [True, False, False, True]\\11: [False, True, False, True]\\12: [False, False, False, False]\\13: [True, False, False, False]\\14: [False, False, False, True]\\15: [False, False, True, False]\\16: [True, True, True, False]\\17: [True, False, False, False]\\18: [True, True, False, True]\\19: [True, False, False, True]\\20: [False, False, False, True]\\}{39}
\begin{questions}
\begin{multicols}{2}

\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [True, False, False, True]\\3: [False, True, False, False]\\4: [False, True, True, True]\\5: [False, False, True, True]\\6: [False, True, False, True]\\7: [True, True, True, False]\\8: [True, False, False, False]\\9: [False, False, True, False]\\10: [False, False, True, False]\\11: [False, False, True, False]\\12: [True, True, False, False]\\13: [False, True, False, True]\\14: [True, False, False, False]\\15: [False, False, False, True]\\16: [False, False, True, False]\\17: [False, True, True, True]\\18: [False, True, True, True]\\19: [False, False, True, False]\\20: [False, False, False, True]\\}{40}
\begin{questions}
\begin{multicols}{2}

\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, False]\\2: [True, True, True, False]\\3: [False, False, True, True]\\4: [False, True, False, False]\\5: [False, False, True, False]\\6: [False, False, True, False]\\7: [False, False, False, True]\\8: [True, False, False, False]\\9: [True, False, False, False]\\10: [False, True, False, False]\\11: [True, True, False, False]\\12: [False, False, True, False]\\13: [False, True, False, False]\\14: [False, False, False, True]\\15: [False, True, False, True]\\16: [False, False, True, False]\\17: [True, True, True, False]\\18: [False, True, False, False]\\19: [False, False, False, False]\\20: [True, True, True, True]\\}{41}
\begin{questions}
\begin{multicols}{2}

\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [True, False, True, True]\\3: [False, False, True, False]\\4: [True, True, False, True]\\5: [False, True, False, False]\\6: [True, False, False, True]\\7: [True, True, True, False]\\8: [True, False, True, False]\\9: [True, True, True, True]\\10: [False, True, True, True]\\11: [False, False, False, True]\\12: [True, False, False, False]\\13: [False, False, True, False]\\14: [False, False, False, True]\\15: [True, False, False, False]\\16: [True, False, False, True]\\17: [True, False, False, False]\\18: [False, True, True, False]\\19: [False, False, False, True]\\20: [False, False, False, False]\\}{42}
\begin{questions}
\begin{multicols}{2}

\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [False, False, True, False]\\3: [False, True, False, False]\\4: [False, False, True, False]\\5: [False, False, False, True]\\6: [False, False, False, False]\\7: [False, False, True, False]\\8: [True, False, False, False]\\9: [True, False, False, True]\\10: [False, False, False, True]\\11: [True, True, False, False]\\12: [False, False, True, True]\\13: [False, True, True, True]\\14: [False, True, False, False]\\15: [False, True, False, False]\\16: [True, False, False, False]\\17: [False, False, True, False]\\18: [False, True, False, False]\\19: [True, True, True, False]\\20: [True, False, False, False]\\}{43}
\begin{questions}
\begin{multicols}{2}

\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, False, False, False]\\3: [False, False, False, True]\\4: [False, True, False, True]\\5: [False, True, False, False]\\6: [True, True, True, False]\\7: [True, False, False, False]\\8: [False, False, False, False]\\9: [False, False, False, False]\\10: [False, True, False, False]\\11: [True, False, False, False]\\12: [False, False, False, True]\\13: [False, True, False, False]\\14: [True, True, False, False]\\15: [False, True, True, True]\\16: [False, False, True, False]\\17: [False, True, False, False]\\18: [False, True, True, False]\\19: [True, False, False, False]\\20: [False, True, False, False]\\}{44}
\begin{questions}
\begin{multicols}{2}

\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, False, False]\\2: [False, True, False, False]\\3: [True, False, False, False]\\4: [False, False, True, True]\\5: [False, False, True, False]\\6: [False, True, True, False]\\7: [True, True, False, True]\\8: [True, False, False, False]\\9: [False, False, False, True]\\10: [False, False, True, True]\\11: [True, False, False, True]\\12: [False, False, True, False]\\13: [True, False, False, False]\\14: [False, True, False, True]\\15: [False, True, False, False]\\16: [False, False, False, False]\\17: [False, False, True, False]\\18: [True, True, True, False]\\19: [True, True, True, True]\\20: [False, False, False, True]\\}{45}
\begin{questions}
\begin{multicols}{2}

\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, False]\\2: [True, True, False, False]\\3: [False, True, False, False]\\4: [True, False, False, False]\\5: [False, True, False, False]\\6: [False, True, False, False]\\7: [True, True, True, False]\\8: [True, True, False, False]\\9: [True, False, False, False]\\10: [False, False, False, True]\\11: [False, False, True, False]\\12: [False, False, True, False]\\13: [False, True, True, False]\\14: [False, True, False, False]\\15: [False, False, True, True]\\16: [True, True, True, False]\\17: [True, False, True, False]\\18: [False, False, False, True]\\19: [False, False, True, True]\\20: [False, False, False, True]\\}{46}
\begin{questions}
\begin{multicols}{2}

\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [True, True, False, False]\\3: [False, True, False, False]\\4: [True, False, False, False]\\5: [True, False, False, False]\\6: [True, False, True, False]\\7: [False, True, False, False]\\8: [False, False, True, True]\\9: [False, False, False, False]\\10: [False, False, True, False]\\11: [False, False, True, False]\\12: [False, True, True, True]\\13: [False, True, True, False]\\14: [True, False, True, True]\\15: [True, False, False, False]\\16: [False, False, True, False]\\17: [False, False, True, False]\\18: [False, False, True, False]\\19: [False, True, True, True]\\20: [False, False, False, True]\\}{47}
\begin{questions}
\begin{multicols}{2}

\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, True]\\2: [False, False, True, False]\\3: [False, True, False, True]\\4: [True, True, False, True]\\5: [False, False, True, False]\\6: [False, False, False, True]\\7: [False, False, True, True]\\8: [False, False, False, True]\\9: [False, False, False, False]\\10: [False, True, False, False]\\11: [True, False, False, False]\\12: [True, False, False, False]\\13: [False, False, False, True]\\14: [False, False, False, True]\\15: [False, False, False, True]\\16: [False, False, True, False]\\17: [True, False, False, False]\\18: [True, False, False, False]\\19: [False, True, True, True]\\20: [False, False, True, False]\\}{48}
\begin{questions}
\begin{multicols}{2}

\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, True]\\2: [False, False, False, True]\\3: [False, False, False, True]\\4: [False, True, False, False]\\5: [True, True, True, False]\\6: [False, False, True, True]\\7: [True, False, False, False]\\8: [False, True, False, False]\\9: [True, True, True, True]\\10: [False, False, False, True]\\11: [True, True, False, True]\\12: [False, True, True, False]\\13: [True, False, False, False]\\14: [False, True, False, False]\\15: [False, False, False, False]\\16: [True, True, False, False]\\17: [False, True, False, True]\\18: [False, True, False, False]\\19: [False, True, True, True]\\20: [False, False, True, False]\\}{49}
\begin{questions}
\begin{multicols}{2}

\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, True, False]\\2: [True, True, False, False]\\3: [True, False, False, True]\\4: [False, False, True, False]\\5: [True, True, False, True]\\6: [False, False, False, False]\\7: [True, True, True, True]\\8: [False, False, False, True]\\9: [False, True, False, False]\\10: [False, True, True, True]\\11: [False, True, True, True]\\12: [False, True, False, False]\\13: [False, True, False, False]\\14: [False, False, False, True]\\15: [False, True, False, False]\\16: [False, False, True, False]\\17: [True, True, False, True]\\18: [False, False, False, False]\\19: [False, False, True, False]\\20: [True, False, False, False]\\}{50}
\begin{questions}
\begin{multicols}{2}

\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [True, True, True, False]\\3: [False, False, False, True]\\4: [False, False, False, True]\\5: [True, True, True, False]\\6: [False, False, False, True]\\7: [False, True, True, True]\\8: [False, False, False, True]\\9: [False, False, False, False]\\10: [False, False, False, True]\\11: [True, True, False, False]\\12: [True, True, False, True]\\13: [True, False, False, False]\\14: [False, False, False, False]\\15: [True, True, False, True]\\16: [False, False, True, False]\\17: [False, False, True, False]\\18: [False, True, False, False]\\19: [False, True, False, False]\\20: [False, False, True, False]\\}{51}
\begin{questions}
\begin{multicols}{2}

\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, True, True]\\2: [True, True, True, True]\\3: [False, False, True, False]\\4: [True, False, False, True]\\5: [False, False, False, True]\\6: [False, False, True, False]\\7: [False, False, True, False]\\8: [False, True, False, False]\\9: [True, False, False, False]\\10: [False, False, False, True]\\11: [False, False, True, False]\\12: [False, False, False, False]\\13: [False, False, True, True]\\14: [True, True, False, True]\\15: [True, True, True, False]\\16: [False, False, True, True]\\17: [True, True, False, True]\\18: [False, False, False, True]\\19: [False, False, True, True]\\20: [False, True, True, True]\\}{52}
\begin{questions}
\begin{multicols}{2}

\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, True, False, False]\\3: [False, False, True, True]\\4: [False, True, False, True]\\5: [True, True, False, False]\\6: [False, True, False, True]\\7: [False, True, False, True]\\8: [True, False, False, False]\\9: [False, False, True, False]\\10: [True, True, False, False]\\11: [False, False, True, False]\\12: [False, True, False, False]\\13: [False, True, True, False]\\14: [True, False, False, False]\\15: [False, True, False, True]\\16: [True, True, True, False]\\17: [False, False, False, False]\\18: [True, False, False, False]\\19: [False, False, True, False]\\20: [True, False, False, False]\\}{53}
\begin{questions}
\begin{multicols}{2}

\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, False]\\2: [False, True, True, True]\\3: [True, False, False, False]\\4: [True, False, True, True]\\5: [True, False, True, False]\\6: [False, False, False, True]\\7: [True, True, False, True]\\8: [True, True, True, True]\\9: [False, True, True, True]\\10: [False, True, False, False]\\11: [True, False, False, False]\\12: [True, True, False, False]\\13: [False, True, True, True]\\14: [False, True, False, False]\\15: [False, False, True, False]\\16: [False, True, True, False]\\17: [True, False, False, True]\\18: [False, False, True, False]\\19: [False, True, True, False]\\20: [False, True, False, True]\\}{54}
\begin{questions}
\begin{multicols}{2}

\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, False, False]\\2: [False, True, False, True]\\3: [False, False, True, False]\\4: [False, False, False, True]\\5: [False, False, False, False]\\6: [False, False, True, False]\\7: [True, False, True, False]\\8: [True, True, False, True]\\9: [False, False, True, False]\\10: [False, True, True, True]\\11: [True, False, False, False]\\12: [False, True, True, True]\\13: [False, True, False, False]\\14: [True, True, True, False]\\15: [True, False, False, True]\\16: [True, True, False, True]\\17: [False, False, True, False]\\18: [False, False, True, True]\\19: [True, True, False, False]\\20: [False, False, False, True]\\}{55}
\begin{questions}
\begin{multicols}{2}

\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, False, False, True]\\3: [False, True, False, False]\\4: [False, True, False, False]\\5: [False, False, True, False]\\6: [False, False, True, False]\\7: [False, False, False, True]\\8: [True, True, False, False]\\9: [False, False, True, False]\\10: [False, False, True, True]\\11: [False, True, True, False]\\12: [False, True, True, True]\\13: [True, True, False, True]\\14: [True, True, False, False]\\15: [True, True, False, False]\\16: [False, True, False, False]\\17: [False, False, False, True]\\18: [False, True, False, False]\\19: [False, True, False, True]\\20: [False, False, True, False]\\}{56}
\begin{questions}
\begin{multicols}{2}

\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, True, False]\\2: [True, False, False, True]\\3: [False, False, False, True]\\4: [True, False, False, False]\\5: [False, False, False, True]\\6: [False, True, False, False]\\7: [False, True, False, False]\\8: [False, True, False, False]\\9: [True, False, False, True]\\10: [False, True, False, False]\\11: [True, False, False, False]\\12: [True, True, False, False]\\13: [True, False, True, True]\\14: [False, False, True, False]\\15: [False, False, False, True]\\16: [False, True, False, False]\\17: [False, True, True, True]\\18: [False, False, False, True]\\19: [True, True, False, True]\\20: [False, True, True, False]\\}{57}
\begin{questions}
\begin{multicols}{2}

\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, True, True]\\2: [False, False, True, False]\\3: [False, True, True, True]\\4: [False, True, False, False]\\5: [False, True, False, True]\\6: [True, False, False, False]\\7: [False, False, False, True]\\8: [True, False, False, False]\\9: [False, False, True, True]\\10: [False, False, True, False]\\11: [True, False, False, False]\\12: [True, False, False, False]\\13: [False, True, True, True]\\14: [False, False, False, True]\\15: [True, True, False, True]\\16: [False, True, True, False]\\17: [True, True, False, True]\\18: [False, False, False, False]\\19: [True, False, False, False]\\20: [False, False, True, False]\\}{58}
\begin{questions}
\begin{multicols}{2}

\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Con respecto a WordNet y su contribución a las ontologías y la representación del conocimiento en los sistemas de RI, puede afirmarse que:
\begin{choices}
\choice En WordNet, una palabra está asociada a un conjunto de sinónimos (synsets), siendo estas palabras intercambiables en un contexto.
\choice La integración de WordNet en sistemas de RI permite la expansión de consultas y la mejora de la precisión de los resultados al entender mejor el significado de los términos de búsqueda a través de su contexto semántico y las relaciones entre palabras.
\choice WordNet diferencia claramente entre los significados de palabras según su uso en diferentes contextos, lo que permite aplicaciones avanzadas en desambiguación semántica más allá de los sistemas de recomendación y RI.
\choice Una limitación de WordNet en la representación del conocimiento es su enfoque en el idioma inglés, lo que plantea desafíos en la aplicación global y la interoperabilidad con sistemas de información multilingües.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, False, False]\\2: [False, False, True, False]\\3: [True, True, True, False]\\4: [True, False, False, False]\\5: [True, True, True, False]\\6: [False, False, True, False]\\7: [True, False, False, False]\\8: [True, False, True, True]\\9: [False, True, False, True]\\10: [False, True, False, True]\\11: [False, False, False, False]\\12: [True, True, True, True]\\13: [False, True, False, True]\\14: [True, True, False, False]\\15: [True, False, False, False]\\16: [False, False, True, False]\\17: [False, False, True, True]\\18: [False, False, False, True]\\19: [False, True, False, False]\\20: [False, True, False, False]\\}{59}
\begin{questions}
\begin{multicols}{2}

\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question En una biblioteca digital se necesita implementar un sistema que permita a los usuarios encontrar libros y artículos científicos de forma rápida y precisa. Los documentos están en diversos formatos, incluyendo PDF, EPUB y HTML. Se requiere seleccionar un algoritmo de indexación adecuado para el sistema, por lo que el programador designado para la implementación debe considerar:
\begin{choices}
\choice La velocidad de indexación y recuperación de datos.
\choice La capacidad para manejar documentos en diferentes formatos.
\choice La complejidad del algoritmo en términos de implementación y mantenimiento.
\choice La capacidad del algoritmo para procesar imágenes incrustadas o referenciadas en los ficheros.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, False, False, False]\\3: [False, True, False, False]\\4: [False, False, True, False]\\5: [True, True, False, False]\\6: [False, False, True, False]\\7: [True, False, False, True]\\8: [True, False, False, False]\\9: [False, False, True, False]\\10: [True, True, False, False]\\11: [False, False, False, True]\\12: [True, False, False, False]\\13: [True, True, False, True]\\14: [False, True, False, False]\\15: [False, True, True, False]\\16: [False, False, False, True]\\17: [True, True, False, True]\\18: [False, True, False, True]\\19: [True, True, False, True]\\20: [False, False, True, True]\\}{60}
\begin{questions}
\begin{multicols}{2}

\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, True, False]\\2: [False, True, False, False]\\3: [False, True, True, True]\\4: [True, False, False, False]\\5: [False, False, True, False]\\6: [True, False, False, False]\\7: [False, False, True, False]\\8: [False, False, False, True]\\9: [False, True, False, False]\\10: [False, False, False, False]\\11: [False, True, True, True]\\12: [False, False, True, False]\\13: [True, False, False, False]\\14: [False, True, False, False]\\15: [False, True, True, True]\\16: [False, False, False, True]\\17: [False, False, False, True]\\18: [False, False, False, True]\\19: [True, False, False, False]\\20: [True, False, False, False]\\}{61}
\begin{questions}
\begin{multicols}{2}

\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question La transición de la Web 1.0 a la Web 2.0 se caracterizó principalmente por:
\begin{choices}
\choice El aumento en la velocidad de conexión a internet, que permitió una mejor calidad de las páginas web.
\choice La disminución de la importancia de los motores de búsqueda en la navegación web.
\choice El cambio de páginas web estáticas a dinámicas, permitiendo la interacción del usuario y la generación de contenido.
\choice La reducción en el uso de HTML y CSS en el desarrollo de sitios web.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, True, False]\\2: [False, False, True, False]\\3: [True, False, False, False]\\4: [False, True, True, True]\\5: [True, True, False, True]\\6: [True, True, True, True]\\7: [True, False, False, True]\\8: [True, False, False, False]\\9: [False, False, False, True]\\10: [False, True, False, False]\\11: [True, False, False, False]\\12: [False, False, False, False]\\13: [False, False, True, False]\\14: [False, False, True, False]\\15: [True, True, False, False]\\16: [False, False, False, True]\\17: [False, True, False, False]\\18: [False, False, True, False]\\19: [False, False, False, True]\\20: [False, True, False, False]\\}{62}
\begin{questions}
\begin{multicols}{2}

\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [True, True, False, False]\\3: [False, False, False, True]\\4: [True, False, False, True]\\5: [False, True, True, False]\\6: [False, False, False, False]\\7: [False, False, False, True]\\8: [False, True, False, False]\\9: [False, False, True, False]\\10: [False, True, True, True]\\11: [False, False, False, False]\\12: [False, False, False, True]\\13: [False, False, True, True]\\14: [True, True, True, True]\\15: [False, True, False, False]\\16: [False, False, True, False]\\17: [False, False, True, False]\\18: [True, True, False, False]\\19: [False, False, False, True]\\20: [False, False, True, False]\\}{63}
\begin{questions}
\begin{multicols}{2}

\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question Referente al Web Crawler puede afirmarse que:
\begin{choices}
\choice Los hipervínculos encontrados en cada sitio web que no pertenecen al dominio donde fueron encontrados se desechan, puesto que no expande el conjunto de URLs sin visitar.
\choice Las páginas visitadas no se procesan nunca más.
\choice No necesita de un conjunto inicial de URLs para recorrer la Web.
\choice No tiene como objetivo indexar y recopilar información de diferentes sitios web.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question Existen varias estrategias consideradas como no recomendables para mejorar el SEO de un sitio web. Dentro de estas estrategias negativas, se encuentran:
\begin{choices}
\choice Construir enlaces naturales de sitios web con autoridad y relevancia temática.
\choice Evitar el uso de las meta etiquetas y descripciones del sitio web para reflejar el contenido de la página.
\choice Incluir una cantidad excesiva de palabras clave irrelevantes para intentar manipular los rankings de búsqueda.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, False, False]\\2: [True, False, False, False]\\3: [True, False, False, False]\\4: [True, False, False, False]\\5: [True, True, False, True]\\6: [True, False, False, False]\\7: [False, True, False, True]\\8: [False, True, False, True]\\9: [False, True, False, False]\\10: [False, True, False, False]\\11: [False, False, True, False]\\12: [True, True, False, False]\\13: [False, False, False, True]\\14: [False, False, False, False]\\15: [True, True, True, True]\\16: [True, False, False, False]\\17: [False, False, True, False]\\18: [False, False, False, False]\\19: [False, True, False, False]\\20: [False, False, False, True]\\}{64}
\begin{questions}
\begin{multicols}{2}

\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En una red de transporte donde cada nodo es una parada de autobús y las aristas representan si existe un carro que pasa por ambos sitios, ¿qué puede mejorar el sistema de transporte?
\begin{choices}
\choice No considerar la centralidad de intermediación de las estaciones de transporte público al planificar rutas y horarios, ya que no tiene impacto en las conexiones entre las paradas.
\choice Utilizar el grafo inducido de los nodos con mayor valor en la centralidad de grado para aplicar la centralidad de intermediación con el propósito de reforzar las paradas con mayor tráfico.
\choice Utilizar la centralidad de intermediación para identificar las paradas de transferencia clave y establecer nuevas conexiones entre diferentes líneas de transporte público.
\choice No implementar sistemas de información en tiempo real para los usuarios, ya que pueden aumentar la carga de los trabajadores.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question En el diseño de un videojuego de roles (RPG) en el que los personajes tienen atributos como salud, fuerza y velocidad, ¿cuál de las siguientes opciones representa mejor una implementación de la representación del conocimiento orientado a objetos?
\begin{choices}
\choice Cada personaje se representa como una lista de cadenas de texto que describen sus características físicas y habilidades.
\choice Cada personaje se representa como una función que calcula sus atributos en función de su nivel y experiencia.
\choice Cada personaje se representa como una matriz de números que almacena sus valores de atributos.
\choice Cada personaje se representa como un objeto con propiedades como salud, fuerza y velocidad, y métodos para modificar y consultar estos valores.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, False, True]\\2: [False, True, False, False]\\3: [True, True, False, False]\\4: [True, True, False, True]\\5: [True, False, True, True]\\6: [False, True, False, False]\\7: [True, False, False, False]\\8: [False, True, False, False]\\9: [True, True, True, True]\\10: [True, False, False, False]\\11: [False, True, True, True]\\12: [True, False, True, False]\\13: [True, True, False, False]\\14: [True, True, True, True]\\15: [True, True, False, True]\\16: [True, False, False, False]\\17: [False, False, True, False]\\18: [True, True, False, True]\\19: [False, False, True, True]\\20: [False, True, False, False]\\}{65}
\begin{questions}
\begin{multicols}{2}

\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}
\question Para la RI, el análisis de las redes puede:
\begin{choices}
\choice Ayudar a identificar grupos de interés.
\choice Indicar la importancia de una entidad en la transmisión de la información.
\choice Ayudar a comprender la conectividad y la accesibilidad entre las entidades.
\choice Revelar patrones de influencia dentro de una comunidad.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, False, True]\\2: [False, True, False, False]\\3: [False, True, False, False]\\4: [True, True, False, True]\\5: [False, True, False, False]\\6: [False, True, False, False]\\7: [True, True, False, False]\\8: [True, False, False, False]\\9: [False, False, True, False]\\10: [True, True, False, False]\\11: [True, True, False, True]\\12: [False, False, False, True]\\13: [False, True, False, False]\\14: [True, False, False, False]\\15: [False, True, False, False]\\16: [False, True, True, False]\\17: [False, False, False, True]\\18: [True, False, False, True]\\19: [False, True, False, True]\\20: [True, True, False, False]\\}{66}
\begin{questions}
\begin{multicols}{2}

\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Para contribuir positivamente al posicionamiento orgánico de un sitio web en los motores de búsqueda se puede:
\begin{choices}
\choice Crear contenido relevante y de alta calidad que satisfaga las necesidades de información de los usuarios.
\choice Mejorar la velocidad de carga del sitio web y asegurar que sea \emph{responsive} y fácil de usar en dispositivos móviles.
\choice Incluir una densidad alta de palabras clave para asegurar que el sitio web aparezca en tantas búsquedas como sea posible.
\choice Obtener enlaces entrantes de otros sitios web de alta autoridad y relevancia temática.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question El conjunto frontera de URLs en un Web Crawler:
\begin{choices}
\choice Delimita los sitios web que visitará en futuras iteraciones del proceso.
\choice Es similar a un conjunto de URLs que esperan ser visitadas.
\choice Almacena hipervínculos que pertenecen al mismo dominio del conjunto semilla de URLs con que inició el crawler.
\choice Indica las secciones que no pueden ser visitadas de cada sitio web.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, True, False]\\2: [False, False, False, True]\\3: [True, False, False, False]\\4: [False, True, False, False]\\5: [False, True, False, False]\\6: [True, True, False, True]\\7: [False, False, True, False]\\8: [False, False, False, True]\\9: [False, True, False, True]\\10: [False, False, False, True]\\11: [False, False, True, False]\\12: [True, False, False, False]\\13: [True, False, False, False]\\14: [False, False, True, True]\\15: [False, True, False, False]\\16: [True, False, True, False]\\17: [True, True, True, False]\\18: [True, False, False, True]\\19: [False, False, True, False]\\20: [False, False, True, False]\\}{67}
\begin{questions}
\begin{multicols}{2}

\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice El almacenamiento distribuido centraliza todos los datos en un único servidor para facilitar su gestión y mantenimiento.
\choice El almacenamiento distribuido ofrece ventajas significativas en términos de escalabilidad y rendimiento en comparación con el almacenamiento centralizado.
\choice El almacenamiento distribuido reparte los datos en múltiples servidores para mejorar la disponibilidad y la redundancia del sistema.
\choice El almacenamiento distribuido es una técnica obsoleta.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question Si se tiene el conjunto de páginas interconectadas $\{A \rightarrow B, C;  B \rightarrow C; C \rightarrow A\}$, entonces la página con valor más alto de PageRank es: 
\begin{choices}
\choice A y B.
\choice A.
\choice C.
\choice B.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La Web 3 se conoce como:
\begin{choices}
\choice Internet de las cosas.
\choice Web de solo lectura.
\choice Web semántica.
\choice Web de escritura-lectura.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, False, True, False]\\2: [False, False, False, True]\\3: [False, False, True, False]\\4: [False, False, False, True]\\5: [False, True, False, False]\\6: [True, True, False, True]\\7: [True, True, True, False]\\8: [True, False, False, True]\\9: [False, False, True, False]\\10: [False, False, True, False]\\11: [False, False, False, False]\\12: [False, False, False, True]\\13: [False, True, False, True]\\14: [False, False, False, False]\\15: [True, True, False, False]\\16: [True, False, False, True]\\17: [True, False, False, False]\\18: [False, True, False, False]\\19: [True, True, False, False]\\20: [False, True, True, True]\\}{68}
\begin{questions}
\begin{multicols}{2}

\question Implementar índices invertidos en un SRI asegura:
\begin{choices}
\choice Acelerar el proceso de búsqueda al permitir búsquedas directas por contenido en lugar de por título.
\choice Reducir la cantidad de espacio de almacenamiento necesario al comprimir los datos de los documentos.
\choice Facilitar la búsqueda sobre los datos que contienen términos específicos al mantener una lista de datos para cada término único.
\choice Incrementar la seguridad de los datos almacenados al dificultar el acceso directo a la información sin el índice correcto.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Al ``relajar'' el concepto de clique en la detección de comunidades se intenta solucionar:
\begin{choices}
\choice La imposibilidad de conectar nodos distantes.
\choice La necesidad de datos externos para analizar la red.
\choice La uniformidad de los nodos en términos de grado.
\choice El solapamiento y la complejidad computacional.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question Al realizar la optimización de contenido para SEO debe considerarse:
\begin{choices}
\choice Seleccionar las palabras clave al azar.
\choice Utilizar etiquetas de título y meta descripciones únicas y relevantes para cada página.
\choice Incluir palabras clave de manera excesiva en el contenido para mejorar el posicionamiento.
\choice Crear contenido valioso y original que satisfaga las necesidades de los usuarios.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question Sobre WordNet y su aplicación en el procesamiento del lenguaje natural, se puede afirmar que:
\begin{choices}
\choice El diseño de WordNet facilita su integración en aplicaciones multilingües de NLP, aunque su desarrollo original se centró en el inglés.
\choice Aunque WordNet es una herramienta valiosa en el NLP, su estructura no incluye información sobre la frecuencia de uso de las palabras en el lenguaje natural.
\choice Los synsets facilitan la identificación de relaciones semánticas entre palabras, como la hiperonimia y la meronimia, enriqueciendo tareas de NLP.
\choice WordNet proporciona una base para la desambiguación semántica al agrupar palabras con significados similares en synsets.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, True, False, False]\\2: [True, False, False, False]\\3: [False, False, False, True]\\4: [False, True, True, True]\\5: [False, False, False, True]\\6: [False, False, False, True]\\7: [True, False, False, False]\\8: [True, True, True, False]\\9: [False, False, True, True]\\10: [False, False, False, True]\\11: [True, False, False, False]\\12: [False, True, False, False]\\13: [True, False, False, False]\\14: [True, True, False, False]\\15: [False, True, False, False]\\16: [True, True, False, True]\\17: [False, False, True, True]\\18: [False, True, False, False]\\19: [False, True, False, False]\\20: [False, False, True, True]\\}{69}
\begin{questions}
\begin{multicols}{2}

\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question El concepto de \emph{rank sink} en el algoritmo de PageRank representa páginas web:
\begin{choices}
\choice Con distribuciones uniformes de la puntuación de PageRank.
\choice Que tienen una puntuación de PageRank más alta que otras debido a la manipulación de enlaces entrantes y salientes.
\choice Con una baja calidad de contenido y una cantidad insuficiente de enlaces salientes, lo que las hace menos relevantes en los resultados de búsqueda.
\choice Con un alto número de enlaces salientes que no reciben enlaces entrantes, lo que puede afectar negativamente su puntuación de PageRank.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}
\question Para transformar el contenido no estructurado de las páginas web en datos estructurados, el Web Scraping:
\begin{choices}
\choice Extrae información basada en patrones de HTML/CSS.
\choice Analiza los protocolos de red.
\choice Interpreta el código JavaScript en tiempo real.
\choice Convierte de forma automática imágenes a texto.
\end{choices}
\question El algoritmo de PageRank converge si:
\begin{choices}
\choice La norma de la diferencia entre los vectores es menor a un umbral predefinido.
\choice Finaliza la ejecución cuando el número de iteraciones excede un máximo de iteraciones previamente definido.
\choice Se define un factor de normalización en la fórmula de la función.
\choice El algoritmo no se implementa de forma iterativa.
\end{choices}
\question En un SRI la indexación:
\begin{choices}
\choice Consiste en asociar un identificador único a cada dato almacenado en el sistema.
\choice Mejora la experiencia del usuario.
\choice Permite la organización y la categorización de la información.
\choice Facilita la RI relevante.
\end{choices}
\question La centralidad de intermediación de un nodo indica:
\begin{choices}
\choice La cantidad de nodos vecinos directos.
\choice La resistencia del nodo a fallos.
\choice El número total de conexiones entrantes y salientes.
\choice La frecuencia con la que un nodo actúa como puente en el camino más corto entre otros dos nodos.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question Los Web Crawlers se enfrentan a desafíos constantes. Dentro de ellos se encuentran:
\begin{choices}
\choice La dificultad para generar el contenido dinámico en tiempo real.
\choice La modificación del código y la estructura del sitio web.
\choice La incapacidad para interpretar correctamente el lenguaje de programación utilizado en el desarrollo de los sitios web.
\choice La falta de acceso a la base de datos del servidor web para extraer información actualizada.
\end{choices}
\question Si una red cumple la propiedad de ser un grafo de mundo pequeño, entonces se conoce que:
\begin{choices}
\choice El número de componentes fuertemente conexas está relacionado con la cantidad de grafos $K_n$ presentes.
\choice La longitud media del camino entre todo par de vértices es pequeña.
\choice El grafo es un anillo regular de grado 5.
\choice La red posee pocos vértices.
\end{choices}
\question Una empresa de comercio electrónico necesita mejorar su motor de búsqueda para proporcionar resultados más relevantes a sus usuarios. Actualmente, los resultados de la búsqueda no son precisos y los usuarios a menudo encuentran dificultades para encontrar productos específicos. La empresa está considerando implementar una indexación por conceptos para mejorar la relevancia de los resultados de búsqueda. ¿Qué beneficios podría provocar este cambio?
\begin{choices}
\choice Permite adaptarse fácilmente a cambios en el vocabulario y la terminología utilizada en las descripciones de los productos.
\choice Ayuda a identificar automáticamente relaciones entre productos, lo que puede mejorar las recomendaciones personalizadas a los usuarios.
\choice Facilita la visualización de productos al agruparlos por categorías o características comunes.
\choice Mejora la precisión en la búsqueda de productos relacionados, incluso cuando no coinciden exactamente con los términos de búsqueda del usuario.
\end{choices}
\question La web actual se enfrenta a problemas como: 
\begin{choices}
\choice Presencia de grandes volúmenes de datos estructurados.
\choice Presencia de una alta calidad en los datos.
\choice Presencia de datos volátiles y distribuidos.
\choice Heterogeneidad en los datos.
\end{choices}
\question En el contexto de la representación del conocimiento basada en herencia, ¿qué caracteriza a la herencia cancelable?
\begin{choices}
\choice La herencia es el resultado del razonamiento no transitivo.
\choice Las conclusiones no están determinadas y dependen del nodo de interés.
\choice Las propiedades heredadas siempre se mantienen y no pueden anularse.
\choice No existe ambigüedad en las conclusiones obtenidas.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [False, False, True, False]\\2: [False, True, False, False]\\3: [False, False, False, True]\\4: [True, True, False, False]\\5: [False, True, True, True]\\6: [False, True, True, False]\\7: [False, True, False, False]\\8: [False, True, False, False]\\9: [True, False, False, False]\\10: [True, False, False, False]\\11: [True, False, False, True]\\12: [False, False, True, False]\\13: [False, False, True, False]\\14: [True, True, True, True]\\15: [False, False, False, False]\\16: [True, False, False, False]\\17: [True, True, False, False]\\18: [True, False, True, True]\\19: [False, False, False, True]\\20: [False, False, True, False]\\}{70}
\begin{questions}
\begin{multicols}{2}

\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question En el contexto del procesamiento de grandes conjuntos de datos, se puede asegurar que:
\begin{choices}
\choice MapReduce es un enfoque para procesar datos de forma secuencial en un solo servidor para evitar problemas de concurrencia.
\choice MapReduce divide una tarea en múltiples pasos de map y reduce que se ejecutan de forma secuencial en diferentes servidores para mejorar el rendimiento y la escalabilidad.
\choice MapReduce no es adecuado para el procesamiento de datos no estructurados.
\choice MapReduce solo puede manejar pequeñas cantidades de datos y no escala bien a grandes conjuntos de datos.
\end{choices}
\question El uso de Hadoop y MapReduce en el contexto de la RI tiene como objetivo:
\begin{choices}
\choice Automatizar el mantenimiento de sistemas de bases de datos.
\choice Facilitar el análisis en tiempo real de datos de redes sociales.
\choice Mejorar la eficiencia energética en centros de datos.
\choice Procesar y analizar grandes conjuntos de datos para la RI.
\end{choices}
\question El algoritmo Hypertext Induced Topic Selection (HITS) intenta buscar nodos especiales. Estos son conocidos como:
\begin{choices}
\choice Autoridades.
\choice Hubs.
\choice Centrales.
\choice Sensibles.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice El término ``Big Data'' se refiere exclusivamente al volumen de datos que una organización maneja, sin tener en cuenta la velocidad, la variedad y la veracidad de los datos.
\choice Los SRI pueden beneficiarse de MapReduce para mejorar la RI relevante.
\choice MapReduce es un modelo de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
\choice Uno de los desafíos en el procesamiento de Big Data es la capacidad de gestionar y analizar datos provenientes de diversas fuentes y en diferentes formatos de manera eficiente.
\end{choices}
\question En un sistema donde el conocimiento está definido a partir de reglas se puede asegurar que:
\begin{choices}
\choice El nivel de especificidad de las reglas está limitado.
\choice La representación de conocimiento está basada en la lógica proposicional.
\choice El razonamiento se activa en cadena hacia delante.
\choice El orden en que se definen las reglas no altera el razonamiento del sistema.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question En la RI en el contexto de Big Data, se puede asegurar que:
\begin{choices}
\choice La indexación distribuida divide los datos en múltiples fragmentos que se almacenan en varios nodos para permitir búsquedas paralelas y mejorar la escalabilidad.
\choice La indexación distribuida no ofrece ventajas en términos de rendimiento y escalabilidad en comparación con la indexación centralizada.
\choice La indexación distribuida es una técnica obsoleta.
\choice La indexación distribuida almacena todos los datos en un solo servidor para facilitar su acceso y búsqueda.
\end{choices}
\question Analizar una red permite:
\begin{choices}
\choice Detectar posibles tendencias antes de que se conviertan en tendencia.
\choice Obtener predicciones exactas de eventos futuros en mercados financieros.
\choice Evaluar la calidad del contenido de un sitio web.
\choice Encontrar nodos ``sensibles'' o críticos para la red.
\end{choices}
\question La computación evolutiva:
\begin{choices}
\choice No es aplicable en la RI debido a la complejidad de los algoritmos evolutivos.
\choice Solo puede manejar conjuntos de datos pequeños y no es escalable a grandes volúmenes de datos.
\choice Utiliza algoritmos para buscar soluciones óptimas en grandes espacios de búsqueda, lo que la hace adecuada para problemas de optimización en la RI.
\choice Es útil solo para problemas de clasificación de documentos y no para otras tareas de RI en general.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question Se puede afirmar que:
\begin{choices}
\choice No es posible identificar subgrupos dentro de una red utilizando análisis de redes.
\choice La cantidad de conexiones de un nodo siempre indica su influencia en la red.
\choice El tamaño de una red es siempre indicativo de su efectividad en la transmisión de información.
\choice Todas las relaciones en una red tienen la misma importancia para el análisis.
\end{choices}
\question Una plataforma de comercio electrónico desea mejorar la experiencia del usuario al permitir una navegación más personalizada y contextualizada. Actualmente los usuarios tienen dificultades para encontrar productos relevantes debido a la gran cantidad de opciones disponibles. La empresa está interesada en implementar características de la Web 2.5 y la Web Semántica para abordar este problema. ¿Qué características podrían ayudar para ofrecer una navegación más personalizada y contextualizada?
\begin{choices}
\choice La implementación de ontologías y metadatos para enriquecer la descripción de productos y mejorar la precisión de las recomendaciones.
\choice La optimización de la velocidad de carga del sitio web para mejorar la experiencia del usuario y reducir el abandono del carrito de compra.
\choice La integración de redes sociales para permitir la recomendación de productos basada en las preferencias de amigos y contactos.
\choice La incorporación de los productos en tendencia en el mercado.
\end{choices}
\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, False, False]\\2: [False, False, True, False]\\3: [True, False, False, False]\\4: [False, False, True, True]\\5: [True, False, False, False]\\6: [False, True, False, False]\\7: [False, True, False, False]\\8: [False, True, False, False]\\9: [False, False, True, False]\\10: [False, True, False, True]\\11: [False, False, True, False]\\12: [False, True, False, False]\\13: [True, False, False, True]\\14: [True, True, True, True]\\15: [False, False, False, True]\\16: [False, True, False, True]\\17: [False, True, False, False]\\18: [False, False, False, False]\\19: [False, False, True, False]\\20: [False, False, False, True]\\}{71}
\begin{questions}
\begin{multicols}{2}

\question Considerando las prácticas éticas y legales en el Web Scraping, se puede asegurar que:
\begin{choices}
\choice Web Scraping requiere considerar las políticas de \texttt{robots.txt} del sitio web objetivo.
\choice Es importante revisar y respetar los términos de servicio del sitio web, así como las leyes aplicables de protección de datos y derechos de autor, antes de realizar Web Scraping.
\choice Web Scraping sobre datos personales sin consentimiento es generalmente aceptado si los datos se utilizan con fines de investigación.
\choice La extracción de datos mediante Web Scraping siempre es legal, independientemente de las leyes locales sobre derechos de autor y privacidad de datos definidos en los sitios web.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Una buena práctica de SEO para mejorar el posicionamiento de un sitio web en los motores de búsqueda es:
\begin{choices}
\choice Obtener enlaces de otros sitios web relevantes y de calidad que apunten al sitio.
\choice Copiar contenido directamente de otros sitios web populares para aumentar la cantidad de páginas indexadas.
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Llenar el contenido con palabras clave irrelevantes para aumentar la densidad de palabras clave.
\end{choices}
\question Considerando las dimensiones y desafíos inherentes a Big Data puede afirmarse, tomando en cuenta las características clave y las implicaciones para su procesamiento y análisis, que:
\begin{choices}
\choice Big Data se caracteriza principalmente por su pequeño volumen y uniformidad, permitiendo un procesamiento eficiente con mínimas adaptaciones de las herramientas de análisis de datos tradicionales.
\choice Big Data no desafía la capacidad de las herramientas tradicionales de procesamiento de datos para capturar, almacenar, gestionar y analizar efectivamente la información, dada la evolución constante de las capacidades computacionales y algoritmos de optimización.
\choice Aunque Big Data puede incluir datos estructurados, su naturaleza se expande al incorporar grandes cantidades de datos no estructurados y semiestructurados, lo que exige el uso de tecnologías especializadas en almacenamiento y procesamiento como Hadoop y sistemas de bases de datos NoSQL.
\choice Además de su complejidad y diversidad, Big Data introduce desafíos significativos en términos de veracidad y variabilidad al requerir métodos avanzados de limpieza y validación de datos para asegurar la integridad del análisis.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question En el contexto de la RI en redes sociales se puede afirmar que:
\begin{choices}
\choice El análisis de redes sociales se centra exclusivamente en la cantidad de seguidores que tiene un usuario en particular para determinar su influencia en la red.
\choice El análisis de centralidad de intermediación se utiliza para identificar usuarios que son importantes en una red social debido a su posición como ``puentes'' entre diferentes grupos de usuarios.
\choice El análisis de sentimientos se utiliza para determinar la popularidad de una publicación en redes sociales sin tener en cuenta la opinión de los usuarios.
\choice El análisis de redes sociales no es útil para comprender la difusión de información en una red social específica, para ello se utiliza la medida de centralidad de vector propio.
\end{choices}
\question El algoritmo de PageRank puede describirse como un procedimiento utilizado para:
\begin{choices}
\choice Determinar la velocidad de carga de una página web en un navegador.
\choice Calcular la relevancia de una página web en función de la cantidad y calidad de los enlaces que apuntan hacia ella.
\choice Prevenir el spam y el contenido no deseado en las páginas web.
\choice Clasificar las páginas web en función de su edad y autoridad.
\end{choices}
\question ¿Qué es un ``Uniform Resource Locator (URL) Frontier'' en el contexto de Web Crawling?
\begin{choices}
\choice Un protocolo que define cómo se deben formatear las URLs para el crawling.
\choice Una lista prioritaria de URLs que aún no han sido visitadas por el crawler.
\choice Una técnica para filtrar URLs irrelevantes y mejorar la eficiencia del crawling.
\choice Una base de datos que almacena URLs únicas identificadas como recursos en la web.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question Un sistema cuenta con la siguiente información:
\begin{itemize}
\item Juan pertenece a la marina.
\item Juan es capellán (sacerdote encargado de una tarea específica fuera de la parroquia).
\item Los infantes de la marina suelen ser bebedores de cerveza.
\item Un capellán no suele ser bebedor de cerveza.
\item Un bebedor de cerveza suele tener sobrepeso.
\item Por lo general, un infante de la marina está en buena condición física.
\end{itemize}
Si se representa la información en una red de herencia se puede concluir que:
\begin{choices}
\choice No se puede asegurar que Juan sea capellán.
\choice No se puede asegurar que Juan esté en buena condición física.
\choice Juan tiene sobrepeso.
\choice Existen dos razonamientos cancelables.
\end{choices}
\question La premisa básica del algoritmo de PageRank para clasificar páginas web en los resultados de búsqueda es:
\begin{choices}
\choice La antigüedad de la página web es el principal factor para determinar su clasificación.
\choice El contenido y la relevancia de las palabras clave en la página web determinan su posición.
\choice Los enlaces entrantes a una página web desde otras páginas contribuyen a su importancia y clasificación.
\choice La cantidad de visitas que recibe una página web determina su clasificación.
\end{choices}
\question En un sistema de control de tráfico urbano basado en reglas, ¿cuál de las siguientes reglas sería más efectiva para manejar situaciones de congestión en una intersección?
\begin{choices}
\choice Si hay pocos vehículos en la intersección, reducir el tiempo de los semáforos en verde.
\choice Si hay muchos vehículos en la intersección, aumentar el tiempo de los semáforos en verde.
\choice Si hay un vehículo de emergencia en la intersección, detener todos los demás vehículos.
\choice Si hay muchos peatones cruzando la intersección, reducir el tiempo de los semáforos en rojo.
\end{choices}
\question Los algoritmos para detectar comunidades en una red intentan:
\begin{choices}
\choice Buscar conjuntos donde cada nodo de un mismo conjunto tenga características similares al resto de los nodos del conjunto.
\choice Seleccionar aleatoriamente nodos de alto grado y sus vecinos.
\choice Buscar subgrafos tal que no incluyan nodos cuya ausencia desconecte al subgrafo.
\choice Encontrar grupos donde los nodos pertenecientes a los mismos grupos son cercanos bajo cierta métrica y lejanos con respecto a los nodos de otros grupos.
\end{choices}
\question ¿Qué algoritmos permiten obtener información de una red?
\begin{choices}
\choice Índices de centralidad.
\choice Detección de comunidades.
\choice Hypertext Induced Topic Selection (HITS).
\choice PageRank.
\end{choices}
\question El componente responsable de la gestión de recursos y planificación de tareas en Hadoop es:
\begin{choices}
\choice MapReduce.
\choice Hadoop Common.
\choice HDFS.
\choice YARN.
\end{choices}
\question En el modelo de representación del conocimiento basado en herencia se puede asegurar que:
\begin{choices}
\choice La cantidad de padres que puede tener un nodo no es mayor que 4.
\choice Las conclusiones pueden ser canceladas si el grafo es ambiguo.
\choice Solo se usa en entornos referentes a la biología.
\choice El razonamiento deducido está respaldado por al menos un camino dentro del grafo.
\end{choices}
\question La diferencia entre la indexación por tokens y la indexación por conceptos puede definirse como:
\begin{choices}
\choice La indexación por tokens asigna pesos a los términos basados en su importancia relativa, mientras que la indexación por conceptos utiliza un sistema de etiquetado para asociar términos con características generales.
\choice La indexación por tokens divide los datos en términos individuales, mientras que la indexación por conceptos agrupa los datos en categorías definidas.
\choice La indexación por tokens asigna un valor numérico a cada término de los datos, mientras que la indexación por conceptos utiliza algoritmos de encriptación para proteger la privacidad de los datos.
\choice La indexación por tokens normaliza los datos reduciéndolos a su forma básica, mientras que la indexación por conceptos utiliza un método de ordenación para organizar los términos característicos de los datos.
\end{choices}
\question No se considera como técnica para detectar comunidades en una red:
\begin{choices}
\choice Analizar la mutualidad de los enlaces.
\choice Usar el agrupamiento jerárquico.
\choice Utilizar el algoritmo de K-Means.
\choice Encontrar cliques de vértices de grado par.
\end{choices}
\question En el contexto de la RI en redes, se puede afirmar que:
\begin{choices}
\choice La detección de comunidades no es relevante para la RI en redes, ya que se centra únicamente en la estructura de la red sin considerar el contenido.
\choice La detección de comunidades en una red siempre produce resultados objetivos y consistentes independientemente del algoritmo utilizado.
\choice La detección de comunidades ayuda a identificar grupos de nodos altamente conectados entre sí, lo que puede ser útil para comprender la estructura y el contenido de la red.
\choice La detección de comunidades solo se aplica a redes pequeñas y simples, no a redes grandes y complejas.
\end{choices}
\question Un SRI es capaz de:
\begin{choices}
\choice Crear los índices asociados a los datos sin tener que analizar cada dato.
\choice Generar índices invertidos de manera óptima sin considerar el contexto.
\choice Reducir el tiempo de indexación de los datos si utiliza servidores distribuidos dentro de la red para que cada uno ejecute la indexación del mismo conjunto de datos.
\choice No necesitar de ningún almacenamiento externo para alojar los índices de los datos.
\end{choices}

\end{multicols}
\end{questions}
\newpage
\encabezado{15 de julio de 2024}{1: [True, True, False, False]\\2: [True, True, False, True]\\3: [False, False, False, False]\\4: [True, True, False, True]\\5: [False, False, False, True]\\6: [True, False, False, False]\\7: [False, False, True, False]\\8: [False, True, False, True]\\9: [True, False, False, False]\\10: [True, False, False, False]\\11: [False, True, False, False]\\12: [True, True, False, True]\\13: [False, True, False, False]\\14: [True, False, True, True]\\15: [False, False, True, False]\\16: [False, True, False, False]\\17: [False, False, True, False]\\18: [True, False, False, False]\\19: [False, False, True, False]\\20: [False, False, False, True]\\}{72}
\begin{questions}
\begin{multicols}{2}

\question La Web 1.0 se caracteriza por:
\begin{choices}
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Los sitios web se centran en brindar información en lugar de facilitar la colaboración o participación de los usuarios.
\choice Uso de comunidades virtuales para popularizar los sitios web de noticias.
\choice Los propietarios de los sitios web proporcionan contenido de forma periódica.
\end{choices}
\question Se tiene un grafo donde cada nodo es un personaje de cierto libro de cuentos y la existencia de las aristas está definida si dos personajes aparecen en el mismo cuento. Se puede asegurar que:
\begin{choices}
\choice La centralidad de intermediación identifica a los personajes que actúan como conectores entre personajes de cuentos distintos.
\choice La centralidad de grado es útil para identificar los personajes con más conexiones dentro de la red, lo que puede indicar su importancia en el libro.
\choice La centralidad de cercanía ofrece una relación entre la cantidad de vecinos de un nodo con respecto a la longitud máxima de un camino dentro del grafo partiendo del nodo en cuestión.
\choice La centralidad de cercanía indica el grado de conexión de cada personaje con el resto de los personajes de los cuentos del libro.
\end{choices}
\question En un sistema donde el conocimiento está orientado a objetos se puede asegurar que:
\begin{choices}
\choice Se enfatiza la atención a la información de la cual se extrajo el conocimiento.
\choice Los marcos y las bandas son las estructuras utilizadas para la representación del modelo.
\choice No es posible definir especializaciones de los objetos de la vida real dentro del sistema.
\choice Las funciones de agregación dificultan poder establecer relaciones entre los objetos.
\end{choices}
\question El posicionamiento de un sitio web en los motores de búsqueda puede ser afectado por:
\begin{choices}
\choice Utilizar técnicas de encubrimiento para mostrar contenido diferente a lo indexado por los motores de búsqueda.
\choice Contenido sin valor en el sitio web.
\choice Mantener una estructura de URL clara y coherente.
\choice Obtener enlaces de sitios web irrelevantes y de baja calidad.
\end{choices}
\question ¿Qué estrategia utilizan los Web Crawlers para asegurar un rastreo eficiente y respetuoso de los recursos de los sitios web?
\begin{choices}
\choice Ignorar completamente el archivo \texttt{robots.txt} de los sitios web.
\choice Visitar y rastrear todos los enlaces de una página web simultáneamente.
\choice Extraer únicamente contenido multimedia para reducir la carga en los servidores web.
\choice Seguir las directrices del archivo \texttt{robots.txt} y aplicar un retraso entre las solicitudes.
\end{choices}
\question ¿Cuál de las siguientes opciones describe mejor la diferencia clave entre Web Crawling y Web Scraping?
\begin{choices}
\choice Web Crawling se centra en la exploración y recopilación de enlaces de múltiples sitios web, mientras que Web Scraping se enfoca en la extracción específica de datos de páginas web individuales.
\choice Web Crawling se realiza utilizando herramientas de automatización como Selenium WebDriver, mientras que Web Scraping se lleva a cabo mediante el análisis de HTML y CSS.
\choice Web Scraping implica el análisis de la estructura y el contenido de las páginas web para extraer datos, mientras que Web Crawling se refiere a la descarga y almacenamiento de páginas web completas.
\choice Web Scraping es más eficaz para rastrear e indexar contenido web para motores de búsqueda, mientras que Web Crawling se utiliza principalmente para la extracción de datos en proyectos de investigación.
\end{choices}
\question La política de ordenación de URLs en los Web Crawlers tiene como aspecto fundamental:
\begin{choices}
\choice Limitar el acceso de los crawlers a ciertas secciones de un sitio web, evitando el rastreo de URLs consideradas menos importantes o sensibles.
\choice Definir la estructura de la URL de destino, asegurando que estén ordenadas alfabéticamente para facilitar la navegación y la indexación.
\choice Establecer la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\choice Determinar la forma en que los crawlers asignan un valor de relevancia a cada URL para clasificarlas en el índice de búsqueda.
\end{choices}
\question Se tiene una red de ingredientes donde cada uno representa un nodo y las aristas simbolizan que los ingredientes forman parte de una misma receta. Se busca mejorar la experiencia culinaria mediante la elaboración de combinaciones de ingredientes más interesantes y creativas, para lo cual se debe:
\begin{choices}
\choice No considerar la centralidad de grado de los ingredientes, ya que todas las combinaciones de ingredientes son igualmente válidas.
\choice Utilizar la centralidad de grado para identificar los ingredientes menos conectados en la red y tomarlos en cuenta para su inclusión en las combinaciones.
\choice No tener en cuenta la centralidad de grado de los ingredientes para no darle mayor importancia a los ingredientes más comunes.
\choice Utilizar la centralidad de grado para identificar los ingredientes más populares en la red y crear combinaciones que incluyan una variedad de ingredientes menos comunes.
\end{choices}
\question Un investigador necesita recopilar datos de múltiples sitios web para un estudio académico, pero se enfrenta a varios desafíos al realizar el proceso de Web Scraping de manera ética y legal. ¿Cuál de las siguientes opciones describe mejor uno de los desafíos asociados al proceso de Web Scraping?
\begin{choices}
\choice La necesidad de comprender la estructura del sitio web y su código HTML para extraer los datos correctamente.
\choice La disponibilidad limitada de datos en línea que se pueden extraer utilizando técnicas de Web Scraping.
\choice La dificultad para encontrar herramientas de Web Scraping gratuitas y fiables.
\choice La necesidad de estar montado sobre un scrawler que cumpla con todas las políticas.
\end{choices}
\question El propósito de la política de revisitado en los Web Crawlers es:
\begin{choices}
\choice Determinar la frecuencia con la que los crawlers deben volver a visitar una URL específica para mantener la información actualizada en el índice de búsqueda.
\choice Establecer reglas sobre el tiempo máximo que los crawlers pueden pasar en un sitio web durante cada visita para evitar sobrecargar los servidores.
\choice Limitar el acceso de los crawlers a ciertos servidores luego de visitar las páginas alojadas en estos.
\choice Definir la prioridad de rastreo de las URLs, determinando el orden en que los crawlers visitan y procesan cada página web.
\end{choices}
\question En una empresa comercial, se tiene una red donde los nodos corresponden a los empleados y las aristas representan la frecuencia con la que colaboran en las ventas. Se busca mejorar la colaboración entre los empleados para aumentar las ventas totales, por lo que la directiva debe:
\begin{choices}
\choice Utilizar la centralidad de cercanía para identificar los empleados menos cercanos a otros en la red y asignarles tareas individuales para evitar posibles conflictos y desacuerdos en el proceso de colaboración.
\choice Utilizar la centralidad de cercanía para identificar los empleados más cercanos a otros en la red y promover la colaboración entre ellos, facilitando así la comunicación y el intercambio de conocimientos para mejorar las ventas.
\choice No considerar la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que todos los empleados tienen el mismo acceso a la información y los recursos.
\choice No tener en cuenta la centralidad de cercanía de los empleados al diseñar estrategias de colaboración, ya que esto podría introducir complicaciones adicionales en el proceso de trabajo.
\end{choices}
\question La Web 2.0 se caracteriza por:
\begin{choices}
\choice La existencia de sitios web dinámicos e interactivos que permiten a los usuarios participar, comentar e interactuar tanto con los creadores de contenido como con otros usuarios.
\choice El uso de distintas tecnologías para crear experiencias web más interactivas y con mayor capacidad de respuesta.
\choice Las actualizaciones del contenido de los sitios web se efectúa de forma manual dentro del código HTML
\choice Las plataformas ofrecen experiencias a la medida, permitiendo a los usuarios personalizar sus perfiles, recibir recomendaciones ajustadas al contenido y participar en filtrado colaborativo.
\end{choices}
\question La integración de Hadoop y MapReduce en la RI trae como ventaja:
\begin{choices}
\choice La eliminación de la necesidad de sistemas de bases de datos.
\choice La posibilidad de la extracción de información relevante y la generación de resultados significativos de grandes conjuntos de datos.
\choice La garantía de la privacidad absoluta de los datos procesados.
\choice La reducción de los costos operativos a cero.
\end{choices}
\question Dentro del análisis de redes, la centralidad de grado mide la importancia de un nodo basándose en:
\begin{choices}
\choice El grado del nodo.
\choice La cantidad de veces que aparece el nodo en el camino mínimo entre cualquier par de nodos.
\choice La cantidad de vecinos del nodo.
\choice El número de aristas que posee el nodo.
\end{choices}
\question La afirmación que mejor refleja el principio subyacente de PageRank, considerando su importancia en la clasificación de los sitios web, es:
\begin{choices}
\choice PageRank valora más la cantidad de enlaces entrantes a una página web, independientemente de la calidad o relevancia de estos enlaces.
\choice La efectividad de PageRank se basa exclusivamente en el análisis de las palabras clave contenidas en los enlaces entrantes, sin considerar la estructura de enlace de la Web.
\choice El algoritmo de PageRank considera tanto la cantidad como la calidad de los enlaces entrantes, asignando mayor valor a los enlaces provenientes de sitios web considerados como ``importantes''.
\choice PageRank opera bajo el supuesto de que los enlaces entrantes y salientes tienen el mismo impacto en la valoración de la relevancia de una página web.
\end{choices}
\question Dentro del ecosistema de Hadoop, el HDFS se caracteriza por:
\begin{choices}
\choice El modelo de acceso y de escritura de datos en tiempo real.
\choice La tolerancia a fallos mediante la replicación de datos.
\choice El almacenamiento exclusivo para archivos de texto.
\choice La capacidad ilimitada de almacenamiento.
\end{choices}
\question En el algoritmo de Indexación Basada en Clasificación Bloqueada (BSBI), ¿cuál es el paso final para crear un índice invertido para la colección completa de los datos?
\begin{choices}
\choice Eliminar los términos duplicados de los índices.
\choice Indexar cada bloque de forma independiente.
\choice Fusionar los índices invertidos de cada bloque.
\choice Dividir la colección de datos en bloques de tamaño fijo.
\end{choices}
\question Sobre el algoritmo de PageRank, visto en clase, se puede afirmar que:
\begin{choices}
\choice Evalúa la importancia de un sitio web en función de la calidad y cantidad de enlaces entrantes que recibe de otros sitios web.
\choice Solo tiene en cuenta el contenido en un sitio web para determinar su relevancia en los resultados de búsqueda.
\choice Asigna una puntuación alta a los sitios web que tienen un gran número de enlaces entrantes sin tener en cuenta la calidad de esos enlaces.
\choice Asigna una puntuación baja a los sitios web que contienen muchos enlaces salientes, ya que indica una falta de relevancia.
\end{choices}
\question La afirmación que mejor describe la política de amabilidad en los Web Crawlers es:
\begin{choices}
\choice Los crawlers se diseñan para acceder a sitios web sin restricciones y extraer datos de manera agresiva para su indexación.
\choice La política de amabilidad de los Web Crawlers dicta que los crawlers deben priorizar ciertos tipos de contenido sobre otros, ignorando completamente ciertas páginas web.
\choice La política de amabilidad establece pautas y reglas sobre cómo los crawlers deben interactuar con los sitios web para minimizar la carga del servidor y respetar las directivas de los administradores del sitio.
\choice Los Web Crawlers son libres de recopilar datos de cualquier sitio web sin restricciones, independientemente de la cantidad de tráfico que generen.
\end{choices}
\question En un grafo una comunidad es:
\begin{choices}
\choice Un conjunto de nodos que no comparten ninguna similitud estructural o funcional entre sí.
\choice Un conjunto de nodos aislados.
\choice Un conjunto de nodos altamente conectados que forman un subgrafo completamente independiente del resto de la red.
\choice Un conjunto de nodos que están más densamente interconectados entre sí que con los nodos fuera del conjunto.
\end{choices}

\end{multicols}
\end{questions}
    
\end{document}
 
