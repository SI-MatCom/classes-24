{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 6: Recuperación de Imágenes\n",
    "\n",
    "El laboratorio tiene como objetivo implementar un SRI de imágenes. \n",
    "\n",
    "Se conoce que un modelo de recuperación de información es un cuádruplo [$D$, $D$, $F$, $R(q_j, d_j)$] donde:\n",
    "- $D$ es un conjunto de representaciones lógicas de los datos de la colección. \n",
    "- $Q$ es un conjunto compuesto por representaciones lógicas de las necesidades del usuario, denominadas \"consultas\".\n",
    "- $F$ es un framework para modelar las representaciones de los datos, consultas y sus relaciones.\n",
    "- $R$ es una función de ranking que asocia un número real a una consulta $q \\in Q$ y un documento\n",
    "$d \\in D$. La evaluación de esta función establece un cierto orden entre la información de acuerdo a la consulta\n",
    "\n",
    "Para el caso particular de la clase, la tupla variaría en:\n",
    "- $D$: Representación de las imágenes mediantes puntos claves y descriptores (SIFT).\n",
    "- $Q$: Representación de las imágenes mediantes puntos claves y descriptores (SIFT).\n",
    "- $R$: Álgebra Vectorial. Para medir la similitud entre descriptores, se calcula la distancia (generalmente la distancia euclidiana) entre cada par de descriptores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SIFT**: Transformada de Características Invariantes a Escala (Scale-Invariant Feature Transform)\n",
    "SIFT es un algoritmo de procesamiento de imágenes que permite detectar y describir características locales invariantes a escala y rotación; también es parcialmente invariante a cambios de iluminación y perspectiva. Esto significa que las características SIFT de una imagen permanecerán similares incluso si la imagen se escala, rota o ilumina de manera diferente, algo que no se logra con la simple matriz de escala de grises.\n",
    "\n",
    "SIFT identifica puntos de interés únicos (_keypoints_) y genera descriptores que describen de manera detallada los patrones locales alrededor de estos puntos.\n",
    "\n",
    "Los descriptores SIFT, siendo vectores de características compactos y distintivos, permiten comparaciones rápidas y eficientes entre imágenes utilizando métodos de coincidencia de descriptores, como el emparejamiento de vecinos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra dos pares de imágenes: las primeras son la imagen original y las segundas imágenes son variaciones de estas, rotación y traslación respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_help import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_key_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de características de una imagen\n",
    "\n",
    "Durante la clase se utilizará librería `skimage` la cual cuenta con el módulo `feature`, este incluye el detector SIFT que nos servirá para extraer puntos claves y descriptores.\n",
    "\n",
    "Puede describirse 3 pasos para la extracción de las características:\n",
    "1. Detección de Puntos Clave:\n",
    "\n",
    "    Se detectan los puntos clave en la imagen utilizando un algoritmo que busca regiones distintivas, como cambios de contraste significativos, esquinas o bordes.\n",
    "\n",
    "2. Descripción de Región Local:\n",
    "\n",
    "    Para cada punto clave detectado, se define una región alrededor del punto que es invariante a la escala y la rotación.\n",
    "\n",
    "    Esta región se divide en subregiones más pequeñas, y se calculan orientaciones locales basadas en gradientes dentro de estas subregiones.\n",
    "\n",
    "3. Generación del Descriptor:\n",
    "\n",
    "    El descriptor SIFT se construye combinando la información de todas las subregiones alrededor del punto clave.\n",
    "\n",
    "    Cada subregión contribuye con una parte del vector de características del descriptor final.\n",
    "\n",
    "El descriptor resultante es un vector multidimensional que captura las características locales de textura y estructura en la vecindad del punto clave.\n",
    "\n",
    "Acá se muestran dos ejemplos de imágenes con sus puntos característicos:\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"./Samples/keypoints_lana.png\" alt=\"Texto alternativo 1\" width=\"600\" height=\"auto\">\n",
    "    <img src=\"./Samples/messi_keypoints.png\" alt=\"Texto alternativo 2\" width=\"600\" height=\"auto\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite cargar archivos desde un directorio\n",
    "import os\n",
    "\n",
    "# Permite cargar una imagen en memoria desde el fichero que la define\n",
    "from skimage import io\n",
    "\n",
    "# Permite llevar una imagen a escala de grises\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Permite extraer las características de una imagen\n",
    "from skimage.feature import match_descriptors, plot_matches, SIFT\n",
    "\n",
    "# Permite visualizar resultados\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio #1: Implemente una función para extraer las características SIFT de una imagen.\n",
    "\n",
    "###### Pista #1: Considere convertir la imagen a la escala de grises.\n",
    "###### Pista #2: Considere utilizar alguna función propia de la clase SIFT para la detección y extracción de las características necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sift_features(image):\n",
    "    \"\"\"\n",
    "    Extract SIFT features from an input image\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): Input image in RGB format.\n",
    "\n",
    "    Returns:\n",
    "    - keypoints (list): List of detected keypoints.\n",
    "    - descriptors (numpy.ndarray): Array of size Nx128 containing descriptors for each keypoint.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Ejercicio #1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer la imagen usando skimage\n",
    "sample_image = io.imread('./Samples/sample_image.png')\n",
    "sample_keypoints, sample_desciptors = extract_sift_features(sample_image)\n",
    "\n",
    "plot_keypoints(sample_image, sample_keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio #2: Implemente una función para tener todos los datos en la misma representación.\n",
    "\n",
    "###### Pista: Es posible que las imágenes tengan varios canales de colores, luego de ser cargadas en memoria. Para evitar errores futuros y puesto que solo se necesita trabajar con la escala RGB, considere utilizar la siguiente notación `arr[:, :, :3]`, donde `arr` es la imagen luego de ser cargada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(image_paths):\n",
    "    \"\"\"\n",
    "    Process a set of images to generate SIFT features for each\n",
    "\n",
    "    Parameters:\n",
    "    image_paths (list): List of paths to the images in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    features (dict): Dictionary mapping image paths to their extracted SIFT features.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Ejercicio #2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset'\n",
    "image_paths = [os.path.join(dataset_path, file) for file in os.listdir(dataset_path)]\n",
    "dataset = process_corpus(image_paths)\n",
    "\n",
    "# Visualización de los keypoints de la primera imagen del dataset\n",
    "plot_keypoints(io.imread(image_paths[0])[:, :, :3], dataset[image_paths[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo adelante, se considerará la imagen de Pikachu como consulta al sistema efectuada por el usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la imagen \n",
    "query_image = sample_image[:, :, :3]\n",
    "\n",
    "print('Dimensiones de la imagen:', query_image.shape)\n",
    "\n",
    "# Extraer características de la imagen \n",
    "query_keypoints, query_descriptors = extract_sift_features(query_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio #3: Defina una función para establecer la similitud entre los descriptores de dos imágenes.\n",
    "\n",
    "Puede asumir que como imagen trabajará con el conjunto de puntos clave extraído en el primer ejercicio. \n",
    "\n",
    "Además, esta función tiene que devolver las coincidencias (`matches`), las cuales es un array de dimensión $(N, 2)$, donde $N$ es el número de coincidencias encontradas. Cada fila del array contiene dos índices, uno para cada conjunto de descriptores. Estos índices indican los descriptores coincidentes. Por ejemplo, si $matches[i] = [a, b]$ significa que el descriptor $a$ de $D1$ coincide con el descriptor $b$ de $D2$.\n",
    "\n",
    "###### Pista #1: Al inicio importó la función que establece la similitud. \"Esa función\" permite comparar dos conjuntos de descriptores y encontrar coincidencias entre ellos.\n",
    "\n",
    "###### Pista #2: Considere usar el parámetro `cross_check=True` de \"esa función\", para indicar la coincidencia en ambos sentidos, lo cual reduce el número de coincidencias erróneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_match_descriptors(desc1, desc2):\n",
    "    \"\"\"\n",
    "    Compares two sets of SIFT descriptors to find matching keypoints between them.\n",
    "\n",
    "    Parameters:\n",
    "    desc1 (numpy.ndarray): First set of SIFT descriptors.\n",
    "    desc2 (numpy.ndarray): Second set of SIFT descriptors.\n",
    "\n",
    "    Returns:\n",
    "    matches (list): List of matches found between the two descriptor sets.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Ejercicio #3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio #4: Implemente una función para encontrar las 5 imágenes que más se asemejan a la definida en la consulta.\n",
    "\n",
    "###### Pista: Considere la cantidad de puntos coincidentes entre 2 imágenes como la cercanía entre ellas: a mayor coincidencia, más parecida son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_image(query_descriptors, dataset):\n",
    "    \"\"\"\n",
    "    Finds the most similar image in the corpus to a given query image based on SIFT feature matching.\n",
    "    \n",
    "    Parameters:\n",
    "    query_descriptors (numpy.ndarray): Query descriptor.\n",
    "    dataset (dict): Dataset descriptors.\n",
    "\n",
    "    Returns:\n",
    "    similarities (dict): Dictionary with size 5 where keys are image paths and values are tuples containing keypoints and matches.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Ejercicio #4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = find_most_similar_image(query_descriptors, dataset)\n",
    "\n",
    "query_image = rgb2gray(query_image)\n",
    "for path, (keypoints, matches) in similarities:\n",
    "    img = rgb2gray(io.imread(path)[:, :, :3])\n",
    "    fig, ax = plt.subplots(figsize=(11, 8))\n",
    "\n",
    "    plt.gray()\n",
    "\n",
    "    plot_matches(ax, query_image, img, query_keypoints, keypoints, matches=matches)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Original Image vs. Retrivaled Image\\n\" \"(all keypoints and matches)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
